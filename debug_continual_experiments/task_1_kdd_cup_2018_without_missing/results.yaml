best_checkpoint: debug_continual_experiments/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.01
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 1.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.39560201807479745
  NRMSE: 0.7467447308761569
  mean_wQuantileLoss: 0.3000439463556017
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.42611968412529677
  - 0.28797060484066606
  - 0.2526198736159131
  - 0.2217954961815849
  - 0.21678327827248722
  - 0.19982847367646173
  - 0.198210489586927
  - 0.19323122448986396
  - 0.18849697447149083
  - 0.1871192927355878
  - 0.19163975509582087
  - 0.18690930138109252
  - 0.18386651913169771
  - 0.18518950993893668
  - 0.18419961316976696
  - 0.18134514603298157
  - 0.17648522410308942
  - 0.18051527271745726
  - 0.17244369653053582
  - 0.16901539475657046
  - 0.17356682702666149
  - 0.16746501123998314
  - 0.16981069871690124
  - 0.17672759579727426
  - 0.17171491350745782
  - 0.1708487990545109
  - 0.16798719111829996
  - 0.1756885318318382
  - 0.16369950748048723
  - 0.16943746991455555
  - 0.16694451193325222
  - 0.16421135404380038
  - 0.16512782010249794
  - 0.16772009147098288
  - 0.16641175543190911
  - 0.16732160572428256
  - 0.16345528204692528
  - 0.16870289598591626
  - 0.16382060397882015
  - 0.1646214147331193
  - 0.16400025936309248
  - 0.16229046566877514
  - 0.1607607394689694
  - 0.15922642283840105
  - 0.15930173499509692
  - 0.1556525697815232
  - 0.16125877120066434
  - 0.16064062877558172
  - 0.16218397999182343
  - 0.15990165539551526
  - 0.1609397039283067
  - 0.16284750238992274
  - 0.16084498405689374
  - 0.15979731490369886
  - 0.15859080228256062
  - 0.1582812022534199
  - 0.16280804725829512
  - 0.16092709911754355
  - 0.15796560479793698
  - 0.1583954073721543
  - 0.15892604825785384
  - 0.15777086117304862
  - 0.1581063973135315
  - 0.15874474146403372
  - 0.15938371495576575
  - 0.15732209099223837
  - 0.15592680615372956
  - 0.15785317041445524
  - 0.15886671462794766
  - 0.15716536156833172
  - 0.15370441239792854
  val_loss:
  - 0.2909908711910248
  - 0.28797060484066606
  - 0.2526198736159131
  - 0.2217954961815849
  - 0.21678327827248722
  - 0.19982847367646173
  - 0.198210489586927
  - 0.19323122448986396
  - 0.18849697447149083
  - 0.1871192927355878
  - 0.19163975509582087
  - 0.18690930138109252
  - 0.18386651913169771
  - 0.18518950993893668
  - 0.18419961316976696
  - 0.18134514603298157
  - 0.17648522410308942
  - 0.18051527271745726
  - 0.17244369653053582
  - 0.16901539475657046
  - 0.17356682702666149
  - 0.16746501123998314
  - 0.16981069871690124
  - 0.17672759579727426
  - 0.17171491350745782
  - 0.1708487990545109
  - 0.16798719111829996
  - 0.1756885318318382
  - 0.16369950748048723
  - 0.16943746991455555
  - 0.16694451193325222
  - 0.16421135404380038
  - 0.16512782010249794
  - 0.16772009147098288
  - 0.16641175543190911
  - 0.16732160572428256
  - 0.16345528204692528
  - 0.16870289598591626
  - 0.16382060397882015
  - 0.1646214147331193
  - 0.16400025936309248
  - 0.16229046566877514
  - 0.1607607394689694
  - 0.15922642283840105
  - 0.15930173499509692
  - 0.1556525697815232
  - 0.16125877120066434
  - 0.16064062877558172
  - 0.16218397999182343
  - 0.15990165539551526
  - 0.15183985382318496
  - 0.16284750238992274
  - 0.16084498405689374
  - 0.15979731490369886
  - 0.15859080228256062
  - 0.1582812022534199
  - 0.16280804725829512
  - 0.16092709911754355
  - 0.15796560479793698
  - 0.1583954073721543
  - 0.15892604825785384
  - 0.15777086117304862
  - 0.1581063973135315
  - 0.15874474146403372
  - 0.15938371495576575
  - 0.15732209099223837
  - 0.15592680615372956
  - 0.15785317041445524
  - 0.15886671462794766
  - 0.15716536156833172
  - 0.15370441239792854
