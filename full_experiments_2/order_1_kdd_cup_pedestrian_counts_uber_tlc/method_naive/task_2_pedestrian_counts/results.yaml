best_checkpoint: full_experiments_2/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_2_pedestrian_counts/pedestrian_counts_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 336
  dataset: pedestrian_counts
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.0
  lr: 0.0005
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 2
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.20893629695398538
  NRMSE: 0.7295071372709754
  mean_wQuantileLoss: 0.16951262432392425
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.5005803928943351
  - 0.3323619938455522
  - 0.3013159637339413
  - 0.26099690271075815
  - 0.22860551613848656
  - 0.21657406887970865
  - 0.19873245910275728
  - 0.21090626361547038
  - 0.2115443540387787
  - 0.18310762388864532
  - 0.18420180608518422
  - 0.17472436442039907
  - 0.1721846889704466
  - 0.18070821347646415
  - 0.17552075575804338
  - 0.17826252174563706
  - 0.1676602985826321
  - 0.167074287077412
  - 0.16597506403923035
  - 0.16509772470453754
  - 0.16623711836291477
  - 0.16012672119541094
  - 0.15695779642555863
  - 0.15967977710533887
  - 0.1595603347523138
  - 0.1598142801085487
  - 0.1644766021054238
  - 0.17002762854099274
  - 0.1652327214833349
  - 0.15787968639051542
  - 0.15299492183839902
  - 0.15755974617786705
  - 0.16149399272399023
  - 0.15802092658123001
  - 0.18052881862968206
  - 0.1569980988278985
  - 0.15056063706288114
  - 0.14993348310235888
  - 0.14938242023345083
  - 0.15273692307528108
  - 0.15328741946723312
  - 0.15224346006289124
  - 0.1530807102099061
  - 0.15221622510580346
  - 0.1579290372901596
  - 0.150387704372406
  - 0.14754341955995187
  - 0.15003065491328016
  - 0.15658259275369346
  - 0.14772851089946926
  - 0.14566100446972996
  - 0.1498174670850858
  - 0.15289532335009426
  - 0.14641175454016775
  - 0.1455558721208945
  - 0.14981796249048784
  - 0.14922972861677408
  - 0.14904860826209188
  - 0.14683773188153282
  - 0.14143236936070025
  - 0.14866490702843294
  - 0.14648470311658457
  - 0.15155501768458635
  - 0.14738222252344713
  - 0.14672376634553075
  - 0.15238371852319688
  - 0.1439570343354717
  - 0.14354067528620362
  - 0.153075187059585
  - 0.14522697305073962
  - 0.1517393519752659
  val_loss:
  - 0.276515930891037
  - 0.3323619938455522
  - 0.3013159637339413
  - 0.26099690271075815
  - 0.22860551613848656
  - 0.21657406887970865
  - 0.19873245910275728
  - 0.21090626361547038
  - 0.2115443540387787
  - 0.18310762388864532
  - 0.18420180608518422
  - 0.17472436442039907
  - 0.1721846889704466
  - 0.18070821347646415
  - 0.17552075575804338
  - 0.17826252174563706
  - 0.1676602985826321
  - 0.167074287077412
  - 0.16597506403923035
  - 0.16509772470453754
  - 0.16623711836291477
  - 0.16012672119541094
  - 0.15695779642555863
  - 0.15967977710533887
  - 0.1595603347523138
  - 0.1598142801085487
  - 0.1644766021054238
  - 0.17002762854099274
  - 0.1652327214833349
  - 0.15787968639051542
  - 0.15299492183839902
  - 0.15755974617786705
  - 0.16149399272399023
  - 0.15802092658123001
  - 0.18052881862968206
  - 0.1569980988278985
  - 0.15056063706288114
  - 0.14993348310235888
  - 0.14938242023345083
  - 0.15273692307528108
  - 0.15328741946723312
  - 0.15224346006289124
  - 0.1530807102099061
  - 0.15221622510580346
  - 0.1579290372901596
  - 0.150387704372406
  - 0.14754341955995187
  - 0.15003065491328016
  - 0.15658259275369346
  - 0.14772851089946926
  - 0.12160174548625946
  - 0.1498174670850858
  - 0.15289532335009426
  - 0.14641175454016775
  - 0.1455558721208945
  - 0.14981796249048784
  - 0.14922972861677408
  - 0.14904860826209188
  - 0.14683773188153282
  - 0.14143236936070025
  - 0.14866490702843294
  - 0.14648470311658457
  - 0.15155501768458635
  - 0.14738222252344713
  - 0.14672376634553075
  - 0.15238371852319688
  - 0.1439570343354717
  - 0.14354067528620362
  - 0.153075187059585
  - 0.14522697305073962
  - 0.1517393519752659
