best_checkpoint: full_experiments_3/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_score_l1/lambda_reg_0.5/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.5
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l1
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.34158121458838225
  NRMSE: 0.7018418435233651
  mean_wQuantileLoss: 0.2657313020181489
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.4200037420960143
  - 0.28795298794284463
  - 0.24562214163597673
  - 0.22171654272824526
  - 0.20887656533159316
  - 0.1991853779181838
  - 0.19985514937434345
  - 0.19500984088517725
  - 0.19285836728522554
  - 0.19244430761318654
  - 0.18330481159500778
  - 0.18434730783337727
  - 0.18094180058687925
  - 0.17980965977767482
  - 0.18204956460976973
  - 0.1741398741141893
  - 0.18151548790046945
  - 0.17619600292528048
  - 0.17288360896054655
  - 0.1736079174443148
  - 0.16836274549132213
  - 0.1682271240861155
  - 0.16770309786079451
  - 0.17193541617598385
  - 0.17193917487747967
  - 0.16863169241696596
  - 0.1657911878428422
  - 0.16666434181388468
  - 0.1728245567646809
  - 0.1664469361421652
  - 0.1658320538699627
  - 0.1677061269292608
  - 0.16967297246446833
  - 0.16595431650057435
  - 0.1627439102740027
  - 0.1692577861249447
  - 0.16374363243812695
  - 0.16488345758989453
  - 0.15856955386698246
  - 0.1658095241873525
  - 0.16446448309579864
  - 0.1651585383224301
  - 0.16079743875889108
  - 0.16205290710786358
  - 0.16280499001732096
  - 0.15909863804699853
  - 0.1593201202340424
  - 0.1576033306773752
  - 0.16668170224875212
  - 0.16252999065909535
  - 0.16603715770179406
  - 0.1605850484338589
  - 0.1558725266950205
  - 0.158216493553482
  - 0.1567106029833667
  - 0.1600917082396336
  - 0.16228875878732651
  - 0.1590202257502824
  - 0.162610107450746
  - 0.15923900378402323
  - 0.15683131758123636
  - 0.160530952969566
  - 0.16205062298104167
  - 0.15855365403695032
  - 0.15951661625877023
  - 0.1628221290302463
  - 0.15476589248282835
  - 0.15393467497779056
  - 0.15641423902707174
  - 0.1575795192620717
  - 0.1540320788626559
  val_loss:
  - 0.2887607216835022
  - 0.28795298794284463
  - 0.24562214163597673
  - 0.22171654272824526
  - 0.20887656533159316
  - 0.1991853779181838
  - 0.19985514937434345
  - 0.19500984088517725
  - 0.19285836728522554
  - 0.19244430761318654
  - 0.18330481159500778
  - 0.18434730783337727
  - 0.18094180058687925
  - 0.17980965977767482
  - 0.18204956460976973
  - 0.1741398741141893
  - 0.18151548790046945
  - 0.17619600292528048
  - 0.17288360896054655
  - 0.1736079174443148
  - 0.16836274549132213
  - 0.1682271240861155
  - 0.16770309786079451
  - 0.17193541617598385
  - 0.17193917487747967
  - 0.16863169241696596
  - 0.1657911878428422
  - 0.16666434181388468
  - 0.1728245567646809
  - 0.1664469361421652
  - 0.1658320538699627
  - 0.1677061269292608
  - 0.16967297246446833
  - 0.16595431650057435
  - 0.1627439102740027
  - 0.1692577861249447
  - 0.16374363243812695
  - 0.16488345758989453
  - 0.15856955386698246
  - 0.1658095241873525
  - 0.16446448309579864
  - 0.1651585383224301
  - 0.16079743875889108
  - 0.16205290710786358
  - 0.16280499001732096
  - 0.15909863804699853
  - 0.1593201202340424
  - 0.1576033306773752
  - 0.16668170224875212
  - 0.16252999065909535
  - 0.1427044153213501
  - 0.1605850484338589
  - 0.1558725266950205
  - 0.158216493553482
  - 0.1567106029833667
  - 0.1600917082396336
  - 0.16228875878732651
  - 0.1590202257502824
  - 0.162610107450746
  - 0.15923900378402323
  - 0.15683131758123636
  - 0.160530952969566
  - 0.16205062298104167
  - 0.15855365403695032
  - 0.15951661625877023
  - 0.1628221290302463
  - 0.15476589248282835
  - 0.15393467497779056
  - 0.15641423902707174
  - 0.1575795192620717
  - 0.1540320788626559
