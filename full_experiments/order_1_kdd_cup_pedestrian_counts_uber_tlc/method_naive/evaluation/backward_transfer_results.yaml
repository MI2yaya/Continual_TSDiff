backward_transfer_analysis:
  forgetting_metrics: {}
  performance_matrix: {}
setup:
  checkpoints:
  - full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
  - full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_2_pedestrian_counts/pedestrian_counts_checkpoint_best.pth
  - full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_3_uber_tlc_hourly/uber_tlc_hourly_checkpoint_best.pth
  datasets:
  - kdd_cup_2018_without_missing
  - pedestrian_counts
  - uber_tlc_hourly
  num_samples: 100
  num_tasks: 3
task_performance:
- checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
  evaluated_datasets:
  - kdd_cup_2018_without_missing
  results:
  - checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
    dataset: kdd_cup_2018_without_missing
    error: CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.46 GiB total
      capacity; 4.13 GiB already allocated; 99.06 MiB free; 5.26 GiB reserved in total
      by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb
      to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    success: false
  task_id: 1
- checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_2_pedestrian_counts/pedestrian_counts_checkpoint_best.pth
  evaluated_datasets:
  - kdd_cup_2018_without_missing
  - pedestrian_counts
  results:
  - checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_2_pedestrian_counts/pedestrian_counts_checkpoint_best.pth
    dataset: kdd_cup_2018_without_missing
    error: CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.46 GiB total
      capacity; 4.11 GiB already allocated; 101.06 MiB free; 5.26 GiB reserved in
      total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb
      to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    success: false
  - checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_2_pedestrian_counts/pedestrian_counts_checkpoint_best.pth
    dataset: pedestrian_counts
    error: CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.46 GiB total
      capacity; 4.11 GiB already allocated; 101.06 MiB free; 5.26 GiB reserved in
      total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb
      to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    success: false
  task_id: 2
- checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_3_uber_tlc_hourly/uber_tlc_hourly_checkpoint_best.pth
  evaluated_datasets:
  - kdd_cup_2018_without_missing
  - pedestrian_counts
  - uber_tlc_hourly
  results:
  - checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_3_uber_tlc_hourly/uber_tlc_hourly_checkpoint_best.pth
    dataset: kdd_cup_2018_without_missing
    error: CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.46 GiB total
      capacity; 4.11 GiB already allocated; 101.06 MiB free; 5.26 GiB reserved in
      total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb
      to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    success: false
  - checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_3_uber_tlc_hourly/uber_tlc_hourly_checkpoint_best.pth
    dataset: pedestrian_counts
    error: CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.46 GiB total
      capacity; 4.11 GiB already allocated; 101.06 MiB free; 5.26 GiB reserved in
      total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb
      to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    success: false
  - checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_3_uber_tlc_hourly/uber_tlc_hourly_checkpoint_best.pth
    dataset: uber_tlc_hourly
    error: CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.46 GiB total
      capacity; 4.11 GiB already allocated; 101.06 MiB free; 5.26 GiB reserved in
      total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb
      to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    success: false
  task_id: 3
