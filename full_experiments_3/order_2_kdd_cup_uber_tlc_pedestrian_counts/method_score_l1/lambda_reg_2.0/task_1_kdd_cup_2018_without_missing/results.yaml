best_checkpoint: full_experiments_3/order_2_kdd_cup_uber_tlc_pedestrian_counts/method_score_l1/lambda_reg_2.0/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 2.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l1
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.3531538034544173
  NRMSE: 0.7452945370537251
  mean_wQuantileLoss: 0.27903500005975285
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.4182397050317377
  - 0.28309527167584747
  - 0.23795222083572298
  - 0.20846298441756517
  - 0.20178669306915253
  - 0.19308178400387987
  - 0.1914889964973554
  - 0.18680189060978591
  - 0.18125393678201362
  - 0.18106728902785107
  - 0.18590960965957493
  - 0.18728005030425265
  - 0.17931135062826797
  - 0.1771527740638703
  - 0.1786145424703136
  - 0.17780921241501346
  - 0.17777937918435782
  - 0.17600502603454515
  - 0.16686021315399557
  - 0.1710944032529369
  - 0.1672446290613152
  - 0.17200306965969503
  - 0.17015108175110072
  - 0.17026499297935516
  - 0.16730727517278865
  - 0.1709670937852934
  - 0.16947281028842553
  - 0.17266979557462037
  - 0.17139769432833418
  - 0.1627497150329873
  - 0.16430992778623477
  - 0.16263420408358797
  - 0.1691038372227922
  - 0.16355695336824283
  - 0.16503674071282148
  - 0.16349088895367458
  - 0.16085343714803457
  - 0.16207469225628302
  - 0.1672058113035746
  - 0.1626715767197311
  - 0.16074550413759425
  - 0.15624013205524534
  - 0.15985292167169973
  - 0.16538891720119864
  - 0.16087173420237377
  - 0.16225191263947636
  - 0.16263913491275162
  - 0.15936438483186066
  - 0.16410120617365465
  - 0.16451395209878683
  - 0.1569622009410523
  - 0.15775132464477792
  - 0.15944075788138434
  - 0.15655733464518562
  - 0.16055188904283568
  - 0.15958131611114368
  - 0.16442233964335173
  - 0.15718290186487138
  - 0.15840443433262408
  - 0.15405244391877204
  - 0.15986635320587084
  - 0.16027483571087942
  - 0.15349018690176308
  - 0.15830589196411893
  - 0.16071893268963322
  - 0.1541602833312936
  - 0.16102989541832358
  - 0.15632311830995604
  - 0.15613231132738292
  - 0.15227197436615825
  - 0.15988049475708976
  val_loss:
  - 0.24965980648994446
  - 0.28309527167584747
  - 0.23795222083572298
  - 0.20846298441756517
  - 0.20178669306915253
  - 0.19308178400387987
  - 0.1914889964973554
  - 0.18680189060978591
  - 0.18125393678201362
  - 0.18106728902785107
  - 0.18590960965957493
  - 0.18728005030425265
  - 0.17931135062826797
  - 0.1771527740638703
  - 0.1786145424703136
  - 0.17780921241501346
  - 0.17777937918435782
  - 0.17600502603454515
  - 0.16686021315399557
  - 0.1710944032529369
  - 0.1672446290613152
  - 0.17200306965969503
  - 0.17015108175110072
  - 0.17026499297935516
  - 0.16730727517278865
  - 0.1709670937852934
  - 0.16947281028842553
  - 0.17266979557462037
  - 0.17139769432833418
  - 0.1627497150329873
  - 0.16430992778623477
  - 0.16263420408358797
  - 0.1691038372227922
  - 0.16355695336824283
  - 0.16503674071282148
  - 0.16349088895367458
  - 0.16085343714803457
  - 0.16207469225628302
  - 0.1672058113035746
  - 0.1626715767197311
  - 0.16074550413759425
  - 0.15624013205524534
  - 0.15985292167169973
  - 0.16538891720119864
  - 0.16087173420237377
  - 0.16225191263947636
  - 0.16263913491275162
  - 0.15936438483186066
  - 0.16410120617365465
  - 0.16451395209878683
  - 0.13233027160167693
  - 0.15775132464477792
  - 0.15944075788138434
  - 0.15655733464518562
  - 0.16055188904283568
  - 0.15958131611114368
  - 0.16442233964335173
  - 0.15718290186487138
  - 0.15840443433262408
  - 0.15405244391877204
  - 0.15986635320587084
  - 0.16027483571087942
  - 0.15349018690176308
  - 0.15830589196411893
  - 0.16071893268963322
  - 0.1541602833312936
  - 0.16102989541832358
  - 0.15632311830995604
  - 0.15613231132738292
  - 0.15227197436615825
  - 0.15988049475708976
