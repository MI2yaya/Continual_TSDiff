best_checkpoint: full_experiments_3/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_dropout/dropout_rate_0.5/task_3_uber_tlc_hourly/uber_tlc_hourly_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 336
  dataset: uber_tlc_hourly
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.5
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: false
  lambda_reg: 0.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 2
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.22048577206793257
  NRMSE: 0.517842417734588
  mean_wQuantileLoss: 0.21281126778441417
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.6191778641659766
  - 0.39986249268986285
  - 0.3645881535485387
  - 0.3485039244405925
  - 0.34340164926834404
  - 0.3277444300474599
  - 0.33306036959402263
  - 0.3273487974656746
  - 0.32292675331700593
  - 0.3242090141866356
  - 0.31707629666198045
  - 0.3317758607445285
  - 0.318921786500141
  - 0.3279491744469851
  - 0.3231860164087266
  - 0.3208898262819275
  - 0.3233683422440663
  - 0.3139306396478787
  - 0.31659511767793447
  - 0.32085021841339767
  - 0.3178973355097696
  - 0.3133719122270122
  - 0.31673505099024624
  - 0.3165527111850679
  - 0.3163114357739687
  - 0.3096075071953237
  - 0.31260336725972593
  - 0.3061991384020075
  - 0.309769784566015
  - 0.30762002407573164
  - 0.3105088750598952
  - 0.3107579151401296
  - 0.30986715212929994
  - 0.31399493641220033
  - 0.3071289841318503
  - 0.30248137121088803
  - 0.3114729153458029
  - 0.3102694775443524
  - 0.30168858787510544
  - 0.307789474260062
  - 0.3082723297411576
  - 0.3019569533644244
  - 0.3035917504457757
  - 0.30802089208737016
  - 0.30701217404566705
  - 0.3016385925002396
  - 0.30393165023997426
  - 0.30532070249319077
  - 0.3033899406436831
  - 0.3043239397229627
  - 0.30272956483531743
  - 0.29787452262826264
  - 0.301713002147153
  - 0.29964553739409894
  - 0.3024547966197133
  - 0.29658305703196675
  - 0.30208904843311757
  - 0.2969549377448857
  - 0.3032957963878289
  - 0.2994294709060341
  - 0.3025183192221448
  - 0.3007279331795871
  - 0.30110124906059355
  - 0.3046399870654568
  - 0.3010265009943396
  - 0.29939255851786584
  - 0.3035165687324479
  - 0.30076730088330805
  - 0.29680839157663286
  - 0.29668487259186804
  - 0.29620078240986913
  val_loss:
  - 0.3423885881900787
  - 0.39986249268986285
  - 0.3645881535485387
  - 0.3485039244405925
  - 0.34340164926834404
  - 0.3277444300474599
  - 0.33306036959402263
  - 0.3273487974656746
  - 0.32292675331700593
  - 0.3242090141866356
  - 0.31707629666198045
  - 0.3317758607445285
  - 0.318921786500141
  - 0.3279491744469851
  - 0.3231860164087266
  - 0.3208898262819275
  - 0.3233683422440663
  - 0.3139306396478787
  - 0.31659511767793447
  - 0.32085021841339767
  - 0.3178973355097696
  - 0.3133719122270122
  - 0.31673505099024624
  - 0.3165527111850679
  - 0.3163114357739687
  - 0.3096075071953237
  - 0.31260336725972593
  - 0.3061991384020075
  - 0.309769784566015
  - 0.30762002407573164
  - 0.3105088750598952
  - 0.3107579151401296
  - 0.30986715212929994
  - 0.31399493641220033
  - 0.3071289841318503
  - 0.30248137121088803
  - 0.3114729153458029
  - 0.3102694775443524
  - 0.30168858787510544
  - 0.307789474260062
  - 0.3082723297411576
  - 0.3019569533644244
  - 0.3035917504457757
  - 0.30802089208737016
  - 0.30701217404566705
  - 0.3016385925002396
  - 0.30393165023997426
  - 0.30532070249319077
  - 0.3033899406436831
  - 0.3043239397229627
  - 0.21284884661436082
  - 0.29787452262826264
  - 0.301713002147153
  - 0.29964553739409894
  - 0.3024547966197133
  - 0.29658305703196675
  - 0.30208904843311757
  - 0.2969549377448857
  - 0.3032957963878289
  - 0.2994294709060341
  - 0.3025183192221448
  - 0.3007279331795871
  - 0.30110124906059355
  - 0.3046399870654568
  - 0.3010265009943396
  - 0.29939255851786584
  - 0.3035165687324479
  - 0.30076730088330805
  - 0.29680839157663286
  - 0.29668487259186804
  - 0.29620078240986913
