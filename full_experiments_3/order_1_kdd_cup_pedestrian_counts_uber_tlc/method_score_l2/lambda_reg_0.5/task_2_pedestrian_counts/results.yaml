best_checkpoint: full_experiments_3/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_score_l2/lambda_reg_0.5/task_2_pedestrian_counts/pedestrian_counts_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 336
  dataset: pedestrian_counts
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.5
  lr: 0.0005
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 2
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.2121807710016832
  NRMSE: 0.7236511867348526
  mean_wQuantileLoss: 0.17470959742573378
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 76
  - 77
  - 78
  - 79
  - 80
  - 81
  - 82
  - 83
  - 84
  - 85
  - 86
  - 87
  - 88
  - 89
  - 90
  - 91
  - 92
  - 93
  - 94
  - 95
  train_loss:
  - 0.6076703381258994
  - 0.4186525106197223
  - 0.3368857541354373
  - 0.29421267902944237
  - 0.26381676527671516
  - 0.24641140759922564
  - 0.2510193655034527
  - 0.22165204014163464
  - 0.21625761163886636
  - 0.21462287404574454
  - 0.21315014956053346
  - 0.21063105401117355
  - 0.20773816225118935
  - 0.20370840886607766
  - 0.20839536329731345
  - 0.2019565935479477
  - 0.1923184598563239
  - 0.20711001998279244
  - 0.19133040658198297
  - 0.1866938362363726
  - 0.20717273617628962
  - 0.22893736080732197
  - 0.19461026915814728
  - 0.19084686669521034
  - 0.18790930416435003
  - 0.18886890483554453
  - 0.1868872430641204
  - 0.19252124254126102
  - 0.1833894091541879
  - 0.1857641926035285
  - 0.18438250536564738
  - 0.18866650067502633
  - 0.19656244688667357
  - 0.19282833684701473
  - 0.19662152556702495
  - 0.18650195957161486
  - 0.18089074059389532
  - 0.18413104442879558
  - 0.18582662660628557
  - 0.18291716964449733
  - 0.18339809373719618
  - 0.2084959409548901
  - 0.18137717311037704
  - 0.1821662134025246
  - 0.18233629985479638
  - 0.179005968850106
  - 0.18146142771001905
  - 0.18045778351370245
  - 0.17851558496477082
  - 0.20831883209757507
  - 0.18255072901956737
  - 0.17857604019809514
  - 0.18166593479691073
  - 0.20618573913816363
  - 0.17529246053891256
  - 0.17903049720916897
  - 0.193718648632057
  - 0.17810793546959758
  - 0.1793613653862849
  - 0.18917900719679892
  - 0.18153728893958032
  - 0.18175126978894696
  - 0.17592769564362243
  - 0.179694595746696
  - 0.1805284817237407
  - 0.17906254436820745
  - 0.17691426014062017
  - 0.18014474801020697
  - 0.17715616791974753
  - 0.18987719557480887
  - 0.17646654462441802
  - 0.17454147833632305
  - 0.17635574890300632
  - 0.17811499553499743
  - 0.17396053613629192
  - 0.17880415834952146
  - 0.17874799232231453
  - 0.18034765037009493
  - 0.17645503400126472
  - 0.185737372841686
  - 0.18047457648208365
  - 0.17694587190635502
  - 0.1742843915708363
  - 0.17833004682324827
  - 0.1791585116297938
  - 0.17950803268468007
  - 0.1781613347120583
  - 0.18124282557982951
  - 0.17484766867710277
  - 0.17435066180769354
  - 0.17845304415095598
  - 0.18409718410111964
  - 0.194124978617765
  - 0.174930325942114
  - 0.17427889059763402
  val_loss:
  - 0.40719926357269287
  - 0.4186525106197223
  - 0.3368857541354373
  - 0.29421267902944237
  - 0.26381676527671516
  - 0.24641140759922564
  - 0.2510193655034527
  - 0.22165204014163464
  - 0.21625761163886636
  - 0.21462287404574454
  - 0.21315014956053346
  - 0.21063105401117355
  - 0.20773816225118935
  - 0.20370840886607766
  - 0.20839536329731345
  - 0.2019565935479477
  - 0.1923184598563239
  - 0.20711001998279244
  - 0.19133040658198297
  - 0.1866938362363726
  - 0.20717273617628962
  - 0.22893736080732197
  - 0.19461026915814728
  - 0.19084686669521034
  - 0.18790930416435003
  - 0.18886890483554453
  - 0.1868872430641204
  - 0.19252124254126102
  - 0.1833894091541879
  - 0.1857641926035285
  - 0.18438250536564738
  - 0.18866650067502633
  - 0.19656244688667357
  - 0.19282833684701473
  - 0.19662152556702495
  - 0.18650195957161486
  - 0.18089074059389532
  - 0.18413104442879558
  - 0.18582662660628557
  - 0.18291716964449733
  - 0.18339809373719618
  - 0.2084959409548901
  - 0.18137717311037704
  - 0.1821662134025246
  - 0.18233629985479638
  - 0.179005968850106
  - 0.18146142771001905
  - 0.18045778351370245
  - 0.17851558496477082
  - 0.20831883209757507
  - 0.3972999304533005
  - 0.17857604019809514
  - 0.18166593479691073
  - 0.20618573913816363
  - 0.17529246053891256
  - 0.17903049720916897
  - 0.193718648632057
  - 0.17810793546959758
  - 0.1793613653862849
  - 0.18917900719679892
  - 0.18153728893958032
  - 0.18175126978894696
  - 0.17592769564362243
  - 0.179694595746696
  - 0.1805284817237407
  - 0.17906254436820745
  - 0.17691426014062017
  - 0.18014474801020697
  - 0.17715616791974753
  - 0.18987719557480887
  - 0.17646654462441802
  - 0.17454147833632305
  - 0.17635574890300632
  - 0.17811499553499743
  - 0.17396053613629192
  - 0.17880415834952146
  - 0.17874799232231453
  - 0.18034765037009493
  - 0.17645503400126472
  - 0.185737372841686
  - 0.18047457648208365
  - 0.17694587190635502
  - 0.1742843915708363
  - 0.17833004682324827
  - 0.1791585116297938
  - 0.17950803268468007
  - 0.1781613347120583
  - 0.18124282557982951
  - 0.17484766867710277
  - 0.17435066180769354
  - 0.17845304415095598
  - 0.18409718410111964
  - 0.194124978617765
  - 0.174930325942114
  - 0.17427889059763402
