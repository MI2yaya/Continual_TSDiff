best_checkpoint: full_experiments_3/order_2_kdd_cup_uber_tlc_pedestrian_counts/method_dropout/dropout_rate_0.3/task_3_pedestrian_counts/pedestrian_counts_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 336
  dataset: pedestrian_counts
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.3
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.0
  lr: 0.0005
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 2
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.20055328872220202
  NRMSE: 0.7167850112375377
  mean_wQuantileLoss: 0.1682897086289476
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.46847899025306106
  - 0.3627343410626054
  - 0.3302113809622824
  - 0.3579360353760421
  - 0.31617988739162683
  - 0.29548598639667034
  - 0.2641165240202099
  - 0.2654009935213253
  - 0.2445691868197173
  - 0.24197636602912098
  - 0.23032816301565617
  - 0.22479035786818713
  - 0.21840625174809247
  - 0.2360103753162548
  - 0.2173773772083223
  - 0.2106668477645144
  - 0.20784563105553389
  - 0.2068986568483524
  - 0.20372878888156265
  - 0.20098409208003432
  - 0.2034506315831095
  - 0.1944832494482398
  - 0.19724283023970202
  - 0.19939242448890582
  - 0.19888247130438685
  - 0.21344414178747684
  - 0.19737951620481908
  - 0.20011306105880067
  - 0.20033094543032348
  - 0.19301783514674753
  - 0.20615206891670823
  - 0.19068759633228183
  - 0.19447672634851187
  - 0.18922440498135984
  - 0.19231399009004235
  - 0.19390254188328981
  - 0.20285123639041558
  - 0.1919486903352663
  - 0.21898162353318185
  - 0.187221885076724
  - 0.19012046960415319
  - 0.18960984982550144
  - 0.20641099812928587
  - 0.1872820210410282
  - 0.18528769083786756
  - 0.185387080127839
  - 0.18522647442296147
  - 0.18797122762771323
  - 0.18412850995082408
  - 0.18637834466062486
  - 0.18122211372246966
  - 0.1872161549399607
  - 0.18434931087540463
  - 0.20852566964458674
  - 0.18351630738470703
  - 0.18451257410924882
  - 0.19034182641189545
  - 0.18453563685761765
  - 0.18266682722605765
  - 0.18894294468918815
  - 0.18979440460680053
  - 0.1794802169315517
  - 0.19005988677963614
  - 0.18337520607747138
  - 0.18454234721139073
  - 0.18277238588780165
  - 0.18355506850639358
  - 0.17670474626356736
  - 0.1818736889399588
  - 0.17931963072624058
  - 0.17795625777216628
  val_loss:
  - 0.5945555716753006
  - 0.3627343410626054
  - 0.3302113809622824
  - 0.3579360353760421
  - 0.31617988739162683
  - 0.29548598639667034
  - 0.2641165240202099
  - 0.2654009935213253
  - 0.2445691868197173
  - 0.24197636602912098
  - 0.23032816301565617
  - 0.22479035786818713
  - 0.21840625174809247
  - 0.2360103753162548
  - 0.2173773772083223
  - 0.2106668477645144
  - 0.20784563105553389
  - 0.2068986568483524
  - 0.20372878888156265
  - 0.20098409208003432
  - 0.2034506315831095
  - 0.1944832494482398
  - 0.19724283023970202
  - 0.19939242448890582
  - 0.19888247130438685
  - 0.21344414178747684
  - 0.19737951620481908
  - 0.20011306105880067
  - 0.20033094543032348
  - 0.19301783514674753
  - 0.20615206891670823
  - 0.19068759633228183
  - 0.19447672634851187
  - 0.18922440498135984
  - 0.19231399009004235
  - 0.19390254188328981
  - 0.20285123639041558
  - 0.1919486903352663
  - 0.21898162353318185
  - 0.187221885076724
  - 0.19012046960415319
  - 0.18960984982550144
  - 0.20641099812928587
  - 0.1872820210410282
  - 0.18528769083786756
  - 0.185387080127839
  - 0.18522647442296147
  - 0.18797122762771323
  - 0.18412850995082408
  - 0.18637834466062486
  - 0.11557467095553875
  - 0.1872161549399607
  - 0.18434931087540463
  - 0.20852566964458674
  - 0.18351630738470703
  - 0.18451257410924882
  - 0.19034182641189545
  - 0.18453563685761765
  - 0.18266682722605765
  - 0.18894294468918815
  - 0.18979440460680053
  - 0.1794802169315517
  - 0.19005988677963614
  - 0.18337520607747138
  - 0.18454234721139073
  - 0.18277238588780165
  - 0.18355506850639358
  - 0.17670474626356736
  - 0.1818736889399588
  - 0.17931963072624058
  - 0.17795625777216628
