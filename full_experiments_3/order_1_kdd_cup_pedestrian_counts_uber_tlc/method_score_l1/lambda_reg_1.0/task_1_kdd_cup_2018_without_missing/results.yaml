best_checkpoint: full_experiments_3/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_score_l1/lambda_reg_1.0/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 1.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l1
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.29678007414083557
  NRMSE: 0.6981410946948459
  mean_wQuantileLoss: 0.23967850211695063
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.4226980701787397
  - 0.28761935455258936
  - 0.23753595852758735
  - 0.21851877361768857
  - 0.21302702015964314
  - 0.20750273345038295
  - 0.19146757991984487
  - 0.19421082478947937
  - 0.18969425547402352
  - 0.18679344339761883
  - 0.18221940635703504
  - 0.1830331413075328
  - 0.18465555284637958
  - 0.17969548254041
  - 0.1774546067463234
  - 0.18301223893649876
  - 0.17524642689386383
  - 0.17518425575690344
  - 0.17860269453376532
  - 0.1762041585170664
  - 0.17295493243727833
  - 0.17320525308605283
  - 0.16751045279670507
  - 0.17545793007593602
  - 0.1667860794113949
  - 0.1700110210222192
  - 0.17370010417653248
  - 0.1643672133795917
  - 0.16891920182388276
  - 0.1638398626819253
  - 0.16882240655831993
  - 0.1694344725110568
  - 0.1656630946090445
  - 0.16219656629255041
  - 0.16875332972267643
  - 0.16856912430375814
  - 0.1667172188172117
  - 0.16580571531085297
  - 0.16608750342857093
  - 0.16631217813119292
  - 0.1646711669745855
  - 0.15771051502088085
  - 0.16788843489484861
  - 0.16310811758739874
  - 0.1623684259247966
  - 0.1614097753772512
  - 0.16658732324140146
  - 0.16434593679150566
  - 0.16432468924904242
  - 0.1602274933247827
  - 0.1639616917236708
  - 0.164172348449938
  - 0.15869144792668521
  - 0.16233606467721984
  - 0.1614014087826945
  - 0.1644378138007596
  - 0.15978745196480304
  - 0.16460453532636166
  - 0.16209745412925258
  - 0.15950560820056126
  - 0.15958899079123512
  - 0.1602037523407489
  - 0.16067455022130162
  - 0.16346531419549137
  - 0.15910254331538454
  - 0.16159248386975378
  - 0.15843729773769155
  - 0.15888125757919624
  - 0.15611202956642956
  - 0.1564908068976365
  - 0.15672794950660318
  val_loss:
  - 0.30638242661952975
  - 0.28761935455258936
  - 0.23753595852758735
  - 0.21851877361768857
  - 0.21302702015964314
  - 0.20750273345038295
  - 0.19146757991984487
  - 0.19421082478947937
  - 0.18969425547402352
  - 0.18679344339761883
  - 0.18221940635703504
  - 0.1830331413075328
  - 0.18465555284637958
  - 0.17969548254041
  - 0.1774546067463234
  - 0.18301223893649876
  - 0.17524642689386383
  - 0.17518425575690344
  - 0.17860269453376532
  - 0.1762041585170664
  - 0.17295493243727833
  - 0.17320525308605283
  - 0.16751045279670507
  - 0.17545793007593602
  - 0.1667860794113949
  - 0.1700110210222192
  - 0.17370010417653248
  - 0.1643672133795917
  - 0.16891920182388276
  - 0.1638398626819253
  - 0.16882240655831993
  - 0.1694344725110568
  - 0.1656630946090445
  - 0.16219656629255041
  - 0.16875332972267643
  - 0.16856912430375814
  - 0.1667172188172117
  - 0.16580571531085297
  - 0.16608750342857093
  - 0.16631217813119292
  - 0.1646711669745855
  - 0.15771051502088085
  - 0.16788843489484861
  - 0.16310811758739874
  - 0.1623684259247966
  - 0.1614097753772512
  - 0.16658732324140146
  - 0.16434593679150566
  - 0.16432468924904242
  - 0.1602274933247827
  - 0.14384839683771133
  - 0.164172348449938
  - 0.15869144792668521
  - 0.16233606467721984
  - 0.1614014087826945
  - 0.1644378138007596
  - 0.15978745196480304
  - 0.16460453532636166
  - 0.16209745412925258
  - 0.15950560820056126
  - 0.15958899079123512
  - 0.1602037523407489
  - 0.16067455022130162
  - 0.16346531419549137
  - 0.15910254331538454
  - 0.16159248386975378
  - 0.15843729773769155
  - 0.15888125757919624
  - 0.15611202956642956
  - 0.1564908068976365
  - 0.15672794950660318
