best_checkpoint: full_experiments_3/order_2_kdd_cup_uber_tlc_pedestrian_counts/method_dropout/dropout_rate_0.1/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.1
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.31461858378854396
  NRMSE: 0.6773000495789372
  mean_wQuantileLoss: 0.2476465435642704
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.4224566253833473
  - 0.30169927526731044
  - 0.26332530623767525
  - 0.22663589660078287
  - 0.2254441698314622
  - 0.21177197730867192
  - 0.21518889477010816
  - 0.2023684051237069
  - 0.2071301059331745
  - 0.20383900083834305
  - 0.195698375988286
  - 0.1954002776183188
  - 0.19557925657136366
  - 0.20351510908221826
  - 0.1859025892917998
  - 0.18509687489131466
  - 0.18418186926282942
  - 0.1820585989044048
  - 0.17867340077646077
  - 0.1819216218427755
  - 0.18329010513843969
  - 0.18183509446680546
  - 0.18968986731488258
  - 0.17937944125151262
  - 0.17793393618194386
  - 0.1795158457243815
  - 0.17968183860648423
  - 0.17555097670992836
  - 0.17343049024930224
  - 0.17447671969421208
  - 0.17312591237714514
  - 0.16961902857292444
  - 0.17253422481007874
  - 0.17481977312127128
  - 0.17214404453989118
  - 0.1794366764370352
  - 0.17403474648017436
  - 0.17089916940312833
  - 0.17471405596006662
  - 0.1694425162859261
  - 0.17435749672586098
  - 0.1685371159692295
  - 0.16980799322482198
  - 0.16797332209534943
  - 0.17066528904251754
  - 0.16923339548520744
  - 0.16631585609866306
  - 0.17174573871307075
  - 0.17156933911610395
  - 0.1662947327713482
  - 0.17271019867621362
  - 0.16795160761103034
  - 0.16515928850276396
  - 0.1660488797351718
  - 0.16441882628714666
  - 0.16912329551996663
  - 0.17222920042695478
  - 0.16348179226042703
  - 0.1665455810725689
  - 0.16774354153312743
  - 0.16579728783108294
  - 0.1649298542761244
  - 0.164742348191794
  - 0.16704350023064762
  - 0.16642481839517131
  - 0.16312411229591817
  - 0.16230918397195637
  - 0.16351425612811
  - 0.16301654325798154
  - 0.16794789087725803
  - 0.1655441870680079
  val_loss:
  - 0.28566068708896636
  - 0.30169927526731044
  - 0.26332530623767525
  - 0.22663589660078287
  - 0.2254441698314622
  - 0.21177197730867192
  - 0.21518889477010816
  - 0.2023684051237069
  - 0.2071301059331745
  - 0.20383900083834305
  - 0.195698375988286
  - 0.1954002776183188
  - 0.19557925657136366
  - 0.20351510908221826
  - 0.1859025892917998
  - 0.18509687489131466
  - 0.18418186926282942
  - 0.1820585989044048
  - 0.17867340077646077
  - 0.1819216218427755
  - 0.18329010513843969
  - 0.18183509446680546
  - 0.18968986731488258
  - 0.17937944125151262
  - 0.17793393618194386
  - 0.1795158457243815
  - 0.17968183860648423
  - 0.17555097670992836
  - 0.17343049024930224
  - 0.17447671969421208
  - 0.17312591237714514
  - 0.16961902857292444
  - 0.17253422481007874
  - 0.17481977312127128
  - 0.17214404453989118
  - 0.1794366764370352
  - 0.17403474648017436
  - 0.17089916940312833
  - 0.17471405596006662
  - 0.1694425162859261
  - 0.17435749672586098
  - 0.1685371159692295
  - 0.16980799322482198
  - 0.16797332209534943
  - 0.17066528904251754
  - 0.16923339548520744
  - 0.16631585609866306
  - 0.17174573871307075
  - 0.17156933911610395
  - 0.1662947327713482
  - 0.1410253256559372
  - 0.16795160761103034
  - 0.16515928850276396
  - 0.1660488797351718
  - 0.16441882628714666
  - 0.16912329551996663
  - 0.17222920042695478
  - 0.16348179226042703
  - 0.1665455810725689
  - 0.16774354153312743
  - 0.16579728783108294
  - 0.1649298542761244
  - 0.164742348191794
  - 0.16704350023064762
  - 0.16642481839517131
  - 0.16312411229591817
  - 0.16230918397195637
  - 0.16351425612811
  - 0.16301654325798154
  - 0.16794789087725803
  - 0.1655441870680079
