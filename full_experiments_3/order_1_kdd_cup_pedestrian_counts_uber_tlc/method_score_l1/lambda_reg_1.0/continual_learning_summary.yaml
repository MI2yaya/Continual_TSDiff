continual_learning_setup:
  method: score_l1
  method_params:
    lambda_reg: 1.0
  num_tasks: 3
  task_sequence:
  - train_kdd_cup.yaml
  - train_pedestrian_counts.yaml
  - train_uber_tlc.yaml
task_results:
- config_path: ./configs/train_tsdiff/train_kdd_cup.yaml
  dataset: kdd_cup_2018_without_missing
  results:
    best_checkpoint: full_experiments_3/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_score_l1/lambda_reg_1.0/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
    config:
      batch_size: 64
      context_length: 312
      dataset: kdd_cup_2018_without_missing
      device: cuda:1
      diffusion_config: diffusion_small_config
      dropout_rate: 0.0
      eval_every: 50
      freq: H
      gradient_clip_val: 0.5
      init_skip: true
      lambda_reg: 1.0
      lr: 0.001
      max_epochs: 1000
      model: unconditional
      normalization: mean
      num_batches_per_epoch: 128
      num_samples: 16
      prediction_length: 24
      sampler: ddpm
      sampler_params:
        guidance: quantile
        scale: 1
      score_loss_type: l1
      setup: forecasting
      use_features: false
      use_lags: true
      use_validation_set: true
    metrics:
    - ND: 0.29678007414083557
      NRMSE: 0.6981410946948459
      mean_wQuantileLoss: 0.23967850211695063
      missing_scenario: none
      missing_values: 0
    training_history:
      epochs:
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
      - 7
      - 8
      - 9
      - 10
      - 11
      - 12
      - 13
      - 14
      - 15
      - 16
      - 17
      - 18
      - 19
      - 20
      - 21
      - 22
      - 23
      - 24
      - 25
      - 26
      - 27
      - 28
      - 29
      - 30
      - 31
      - 32
      - 33
      - 34
      - 35
      - 36
      - 37
      - 38
      - 39
      - 40
      - 41
      - 42
      - 43
      - 44
      - 45
      - 46
      - 47
      - 48
      - 49
      - 50
      - 51
      - 52
      - 53
      - 54
      - 55
      - 56
      - 57
      - 58
      - 59
      - 60
      - 61
      - 62
      - 63
      - 64
      - 65
      - 66
      - 67
      - 68
      - 69
      - 70
      - 71
      train_loss:
      - 0.4226980701787397
      - 0.28761935455258936
      - 0.23753595852758735
      - 0.21851877361768857
      - 0.21302702015964314
      - 0.20750273345038295
      - 0.19146757991984487
      - 0.19421082478947937
      - 0.18969425547402352
      - 0.18679344339761883
      - 0.18221940635703504
      - 0.1830331413075328
      - 0.18465555284637958
      - 0.17969548254041
      - 0.1774546067463234
      - 0.18301223893649876
      - 0.17524642689386383
      - 0.17518425575690344
      - 0.17860269453376532
      - 0.1762041585170664
      - 0.17295493243727833
      - 0.17320525308605283
      - 0.16751045279670507
      - 0.17545793007593602
      - 0.1667860794113949
      - 0.1700110210222192
      - 0.17370010417653248
      - 0.1643672133795917
      - 0.16891920182388276
      - 0.1638398626819253
      - 0.16882240655831993
      - 0.1694344725110568
      - 0.1656630946090445
      - 0.16219656629255041
      - 0.16875332972267643
      - 0.16856912430375814
      - 0.1667172188172117
      - 0.16580571531085297
      - 0.16608750342857093
      - 0.16631217813119292
      - 0.1646711669745855
      - 0.15771051502088085
      - 0.16788843489484861
      - 0.16310811758739874
      - 0.1623684259247966
      - 0.1614097753772512
      - 0.16658732324140146
      - 0.16434593679150566
      - 0.16432468924904242
      - 0.1602274933247827
      - 0.1639616917236708
      - 0.164172348449938
      - 0.15869144792668521
      - 0.16233606467721984
      - 0.1614014087826945
      - 0.1644378138007596
      - 0.15978745196480304
      - 0.16460453532636166
      - 0.16209745412925258
      - 0.15950560820056126
      - 0.15958899079123512
      - 0.1602037523407489
      - 0.16067455022130162
      - 0.16346531419549137
      - 0.15910254331538454
      - 0.16159248386975378
      - 0.15843729773769155
      - 0.15888125757919624
      - 0.15611202956642956
      - 0.1564908068976365
      - 0.15672794950660318
      val_loss:
      - 0.30638242661952975
      - 0.28761935455258936
      - 0.23753595852758735
      - 0.21851877361768857
      - 0.21302702015964314
      - 0.20750273345038295
      - 0.19146757991984487
      - 0.19421082478947937
      - 0.18969425547402352
      - 0.18679344339761883
      - 0.18221940635703504
      - 0.1830331413075328
      - 0.18465555284637958
      - 0.17969548254041
      - 0.1774546067463234
      - 0.18301223893649876
      - 0.17524642689386383
      - 0.17518425575690344
      - 0.17860269453376532
      - 0.1762041585170664
      - 0.17295493243727833
      - 0.17320525308605283
      - 0.16751045279670507
      - 0.17545793007593602
      - 0.1667860794113949
      - 0.1700110210222192
      - 0.17370010417653248
      - 0.1643672133795917
      - 0.16891920182388276
      - 0.1638398626819253
      - 0.16882240655831993
      - 0.1694344725110568
      - 0.1656630946090445
      - 0.16219656629255041
      - 0.16875332972267643
      - 0.16856912430375814
      - 0.1667172188172117
      - 0.16580571531085297
      - 0.16608750342857093
      - 0.16631217813119292
      - 0.1646711669745855
      - 0.15771051502088085
      - 0.16788843489484861
      - 0.16310811758739874
      - 0.1623684259247966
      - 0.1614097753772512
      - 0.16658732324140146
      - 0.16434593679150566
      - 0.16432468924904242
      - 0.1602274933247827
      - 0.14384839683771133
      - 0.164172348449938
      - 0.15869144792668521
      - 0.16233606467721984
      - 0.1614014087826945
      - 0.1644378138007596
      - 0.15978745196480304
      - 0.16460453532636166
      - 0.16209745412925258
      - 0.15950560820056126
      - 0.15958899079123512
      - 0.1602037523407489
      - 0.16067455022130162
      - 0.16346531419549137
      - 0.15910254331538454
      - 0.16159248386975378
      - 0.15843729773769155
      - 0.15888125757919624
      - 0.15611202956642956
      - 0.1564908068976365
      - 0.15672794950660318
  task_id: 1
- config_path: ./configs/train_tsdiff/train_pedestrian_counts.yaml
  dataset: pedestrian_counts
  results:
    best_checkpoint: full_experiments_3/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_score_l1/lambda_reg_1.0/task_2_pedestrian_counts/pedestrian_counts_checkpoint_best.pth
    config:
      batch_size: 64
      context_length: 336
      dataset: pedestrian_counts
      device: cuda:1
      diffusion_config: diffusion_small_config
      dropout_rate: 0.0
      eval_every: 50
      freq: H
      gradient_clip_val: 0.5
      init_skip: true
      lambda_reg: 1.0
      lr: 0.0005
      max_epochs: 1000
      model: unconditional
      normalization: mean
      num_batches_per_epoch: 128
      prediction_length: 24
      sampler: ddpm
      sampler_params:
        guidance: quantile
        scale: 2
      score_loss_type: l1
      setup: forecasting
      use_features: false
      use_lags: true
      use_validation_set: true
    metrics:
    - ND: 0.24882269818971453
      NRMSE: 0.8672846849320092
      mean_wQuantileLoss: 0.24801823835043754
      missing_scenario: none
      missing_values: 0
    training_history:
      epochs:
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
      - 7
      - 8
      - 9
      - 10
      - 11
      - 12
      - 13
      - 14
      - 15
      - 16
      - 17
      - 18
      - 19
      - 20
      - 21
      train_loss:
      - 0.8250631478149444
      - 0.5770995239727199
      - 0.506829786580056
      - 0.45409324346110225
      - 0.4187450157478452
      - 0.39739062753506005
      - 0.3749900567345321
      - 0.36158822826109827
      - 0.34707541950047016
      - 0.3465024579782039
      - 0.33560470095835626
      - 0.3449620420578867
      - 0.3261417482281104
      - 0.33429338736459613
      - 0.34250579704530537
      - 0.3195638048928231
      - 0.3250401755794883
      - 0.3170223932247609
      - 0.31470240640919656
      - 0.3087230119854212
      - 0.3292502264957875
      val_loss:
      - 0.23307934403419495
      - 0.5770995239727199
      - 0.506829786580056
      - 0.45409324346110225
      - 0.4187450157478452
      - 0.39739062753506005
      - 0.3749900567345321
      - 0.36158822826109827
      - 0.34707541950047016
      - 0.3465024579782039
      - 0.33560470095835626
      - 0.3449620420578867
      - 0.3261417482281104
      - 0.33429338736459613
      - 0.34250579704530537
      - 0.3195638048928231
      - 0.3250401755794883
      - 0.3170223932247609
      - 0.31470240640919656
      - 0.3087230119854212
      - 0.3292502264957875
  task_id: 2
- config_path: ./configs/train_tsdiff/train_uber_tlc.yaml
  dataset: uber_tlc_hourly
  results:
    best_checkpoint: full_experiments_3/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_score_l1/lambda_reg_1.0/task_3_uber_tlc_hourly/uber_tlc_hourly_checkpoint_best.pth
    config:
      batch_size: 64
      context_length: 336
      dataset: uber_tlc_hourly
      device: cuda:1
      diffusion_config: diffusion_small_config
      dropout_rate: 0.0
      eval_every: 50
      freq: H
      gradient_clip_val: 0.5
      init_skip: false
      lambda_reg: 1.0
      lr: 0.001
      max_epochs: 1000
      model: unconditional
      normalization: mean
      num_batches_per_epoch: 128
      num_samples: 16
      prediction_length: 24
      sampler: ddpm
      sampler_params:
        guidance: quantile
        scale: 2
      score_loss_type: l1
      setup: forecasting
      use_features: false
      use_lags: true
      use_validation_set: true
    metrics:
    - ND: 0.6959400479557384
      NRMSE: 2.611565984935866
      mean_wQuantileLoss: 0.5501500432760621
      missing_scenario: none
      missing_values: 0
    training_history:
      epochs:
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
      - 7
      - 8
      - 9
      - 10
      - 11
      - 12
      - 13
      - 14
      - 15
      - 16
      - 17
      - 18
      - 19
      - 20
      - 21
      train_loss:
      - 1.1548232762143016
      - 1.0682626008056104
      - 1.0483567183837295
      - 1.040366392582655
      - 1.0327012641355395
      - 1.024860471021384
      - 1.0169736612588167
      - 1.008770344313234
      - 1.0129075176082551
      - 1.0096738701686263
      - 1.0054317680187523
      - 0.997697860468179
      - 1.0072966585867107
      - 0.9948011799715459
      - 0.9923071251250803
      - 0.9932051231153309
      - 0.9917534091509879
      - 0.9861534489318728
      - 0.9845482702367008
      - 0.9821877172216773
      - 0.9809075421653688
      val_loss:
      - 0.5585722506046296
      - 1.0682626008056104
      - 1.0483567183837295
      - 1.040366392582655
      - 1.0327012641355395
      - 1.024860471021384
      - 1.0169736612588167
      - 1.008770344313234
      - 1.0129075176082551
      - 1.0096738701686263
      - 1.0054317680187523
      - 0.997697860468179
      - 1.0072966585867107
      - 0.9948011799715459
      - 0.9923071251250803
      - 0.9932051231153309
      - 0.9917534091509879
      - 0.9861534489318728
      - 0.9845482702367008
      - 0.9821877172216773
      - 0.9809075421653688
  task_id: 3
