best_checkpoint: full_experiments_3/order_2_kdd_cup_uber_tlc_pedestrian_counts/method_score_l1/lambda_reg_0.5/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.5
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l1
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.36164181646832716
  NRMSE: 0.7196341412195817
  mean_wQuantileLoss: 0.2819087582922268
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.4161682145204395
  - 0.27313398476690054
  - 0.23289524350548163
  - 0.21121063036844134
  - 0.20016632042825222
  - 0.20016730902716517
  - 0.1965726909111254
  - 0.19147678662557155
  - 0.18959926709067076
  - 0.18790529924444854
  - 0.18709359428612515
  - 0.18472058657789603
  - 0.17150043410947546
  - 0.17627061356324703
  - 0.1777810085332021
  - 0.17642516683554277
  - 0.17691425705561414
  - 0.17509552877163514
  - 0.18277237744769081
  - 0.171078669547569
  - 0.1704982099472545
  - 0.1716840957524255
  - 0.17159985873149708
  - 0.17418573948089033
  - 0.16777092317352071
  - 0.1677237765979953
  - 0.16932396858464926
  - 0.16875717538641766
  - 0.1685716729843989
  - 0.17082892754115164
  - 0.16282012197189033
  - 0.16929573734523728
  - 0.16566458670422435
  - 0.16723556391661987
  - 0.16120033647166565
  - 0.1626094586099498
  - 0.16891016229055822
  - 0.16349148290464655
  - 0.16382209217408672
  - 0.1663863385329023
  - 0.16397455020342022
  - 0.16266450547846034
  - 0.161895937519148
  - 0.16203347739065066
  - 0.1683131626341492
  - 0.15932195913046598
  - 0.16548438288737088
  - 0.17292457452276722
  - 0.16555664979387075
  - 0.16725235630292445
  - 0.1604241299792193
  - 0.157308756664861
  - 0.1586842485703528
  - 0.1632517905673012
  - 0.156947661715094
  - 0.16389556595822796
  - 0.15832183399470523
  - 0.1634954062756151
  - 0.15926823939662427
  - 0.1600243506836705
  - 0.16473877761745825
  - 0.15756616462022066
  - 0.15601429261732846
  - 0.16535283642588183
  - 0.15564235288184136
  - 0.16184288286603987
  - 0.15452720067696646
  - 0.1594976412015967
  - 0.15923641540575773
  - 0.16124559339368716
  - 0.16034853871678934
  val_loss:
  - 0.2871508449316025
  - 0.27313398476690054
  - 0.23289524350548163
  - 0.21121063036844134
  - 0.20016632042825222
  - 0.20016730902716517
  - 0.1965726909111254
  - 0.19147678662557155
  - 0.18959926709067076
  - 0.18790529924444854
  - 0.18709359428612515
  - 0.18472058657789603
  - 0.17150043410947546
  - 0.17627061356324703
  - 0.1777810085332021
  - 0.17642516683554277
  - 0.17691425705561414
  - 0.17509552877163514
  - 0.18277237744769081
  - 0.171078669547569
  - 0.1704982099472545
  - 0.1716840957524255
  - 0.17159985873149708
  - 0.17418573948089033
  - 0.16777092317352071
  - 0.1677237765979953
  - 0.16932396858464926
  - 0.16875717538641766
  - 0.1685716729843989
  - 0.17082892754115164
  - 0.16282012197189033
  - 0.16929573734523728
  - 0.16566458670422435
  - 0.16723556391661987
  - 0.16120033647166565
  - 0.1626094586099498
  - 0.16891016229055822
  - 0.16349148290464655
  - 0.16382209217408672
  - 0.1663863385329023
  - 0.16397455020342022
  - 0.16266450547846034
  - 0.161895937519148
  - 0.16203347739065066
  - 0.1683131626341492
  - 0.15932195913046598
  - 0.16548438288737088
  - 0.17292457452276722
  - 0.16555664979387075
  - 0.16725235630292445
  - 0.14618245959281922
  - 0.157308756664861
  - 0.1586842485703528
  - 0.1632517905673012
  - 0.156947661715094
  - 0.16389556595822796
  - 0.15832183399470523
  - 0.1634954062756151
  - 0.15926823939662427
  - 0.1600243506836705
  - 0.16473877761745825
  - 0.15756616462022066
  - 0.15601429261732846
  - 0.16535283642588183
  - 0.15564235288184136
  - 0.16184288286603987
  - 0.15452720067696646
  - 0.1594976412015967
  - 0.15923641540575773
  - 0.16124559339368716
  - 0.16034853871678934
