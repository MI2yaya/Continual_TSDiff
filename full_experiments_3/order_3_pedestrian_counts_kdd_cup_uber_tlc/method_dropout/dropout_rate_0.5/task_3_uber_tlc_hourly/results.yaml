best_checkpoint: full_experiments_3/order_3_pedestrian_counts_kdd_cup_uber_tlc/method_dropout/dropout_rate_0.5/task_3_uber_tlc_hourly/uber_tlc_hourly_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 336
  dataset: uber_tlc_hourly
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.5
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: false
  lambda_reg: 0.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 2
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.22482333309152785
  NRMSE: 0.5648454942294016
  mean_wQuantileLoss: 0.2188857055616306
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.614834927720949
  - 0.39397172117605805
  - 0.36330513237044215
  - 0.3451197976246476
  - 0.3411021603969857
  - 0.33443602500483394
  - 0.33634612802416086
  - 0.32922798302024603
  - 0.33060354564804584
  - 0.3276146368589252
  - 0.32381102873478085
  - 0.31985116144642234
  - 0.32155903487000614
  - 0.3198238272452727
  - 0.3146786942379549
  - 0.31621940783225
  - 0.3198967649368569
  - 0.3150404173647985
  - 0.31449865363538265
  - 0.3196742683649063
  - 0.31558355886954814
  - 0.31402232218533754
  - 0.3121526464819908
  - 0.3108914525946602
  - 0.31077328347600996
  - 0.3093726618681103
  - 0.3107301751151681
  - 0.3170710453996435
  - 0.3130594561807811
  - 0.31520707276649773
  - 0.3154688876820728
  - 0.3111612608190626
  - 0.31408170866779983
  - 0.3124922792194411
  - 0.30974777147639543
  - 0.3070818354608491
  - 0.3051345720887184
  - 0.3120012659346685
  - 0.31581342255230993
  - 0.3088594488799572
  - 0.3111235913820565
  - 0.30664832913316786
  - 0.3114028135314584
  - 0.3074869238771498
  - 0.30953873007092625
  - 0.30473434331361204
  - 0.30531307589262724
  - 0.30548985628411174
  - 0.30925266444683075
  - 0.2999526619678363
  - 0.30306032637599856
  - 0.30369107355363667
  - 0.30459983681794256
  - 0.3018763264408335
  - 0.30209448700770736
  - 0.29511676530819386
  - 0.29976185597479343
  - 0.303336710203439
  - 0.3039666109252721
  - 0.3016346172662452
  - 0.2993331056786701
  - 0.30771358439233154
  - 0.2987755083013326
  - 0.30373418366070837
  - 0.2972277192166075
  - 0.29978380212560296
  - 0.3012249101884663
  - 0.3000885139917955
  - 0.2985840302426368
  - 0.2912165040615946
  - 0.29833640553988516
  val_loss:
  - 0.328582239151001
  - 0.39397172117605805
  - 0.36330513237044215
  - 0.3451197976246476
  - 0.3411021603969857
  - 0.33443602500483394
  - 0.33634612802416086
  - 0.32922798302024603
  - 0.33060354564804584
  - 0.3276146368589252
  - 0.32381102873478085
  - 0.31985116144642234
  - 0.32155903487000614
  - 0.3198238272452727
  - 0.3146786942379549
  - 0.31621940783225
  - 0.3198967649368569
  - 0.3150404173647985
  - 0.31449865363538265
  - 0.3196742683649063
  - 0.31558355886954814
  - 0.31402232218533754
  - 0.3121526464819908
  - 0.3108914525946602
  - 0.31077328347600996
  - 0.3093726618681103
  - 0.3107301751151681
  - 0.3170710453996435
  - 0.3130594561807811
  - 0.31520707276649773
  - 0.3154688876820728
  - 0.3111612608190626
  - 0.31408170866779983
  - 0.3124922792194411
  - 0.30974777147639543
  - 0.3070818354608491
  - 0.3051345720887184
  - 0.3120012659346685
  - 0.31581342255230993
  - 0.3088594488799572
  - 0.3111235913820565
  - 0.30664832913316786
  - 0.3114028135314584
  - 0.3074869238771498
  - 0.30953873007092625
  - 0.30473434331361204
  - 0.30531307589262724
  - 0.30548985628411174
  - 0.30925266444683075
  - 0.2999526619678363
  - 0.24752054512500762
  - 0.30369107355363667
  - 0.30459983681794256
  - 0.3018763264408335
  - 0.30209448700770736
  - 0.29511676530819386
  - 0.29976185597479343
  - 0.303336710203439
  - 0.3039666109252721
  - 0.3016346172662452
  - 0.2993331056786701
  - 0.30771358439233154
  - 0.2987755083013326
  - 0.30373418366070837
  - 0.2972277192166075
  - 0.29978380212560296
  - 0.3012249101884663
  - 0.3000885139917955
  - 0.2985840302426368
  - 0.2912165040615946
  - 0.29833640553988516
