best_checkpoint: full_experiments_3/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_score_l2/lambda_reg_0.5/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.5
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.3253105403874573
  NRMSE: 0.6847896519891136
  mean_wQuantileLoss: 0.25511926109765565
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.41548542748205364
  - 0.2853026163065806
  - 0.23184308607596904
  - 0.22006177413277328
  - 0.20342857955256477
  - 0.20129437022842467
  - 0.18961070146178827
  - 0.1946948990225792
  - 0.1970863503520377
  - 0.19865133840357885
  - 0.19408059335546568
  - 0.18988457508385181
  - 0.1797778132604435
  - 0.17792674590600654
  - 0.17494741617701948
  - 0.17731583071872592
  - 0.17345176840899512
  - 0.1726633661892265
  - 0.174494112317916
  - 0.17096736055100337
  - 0.17384908528765664
  - 0.17190141696482897
  - 0.17345057765487581
  - 0.16750871611293405
  - 0.16591099399374798
  - 0.17484866408631206
  - 0.16814131365390494
  - 0.15989403001731262
  - 0.17233195510925725
  - 0.1656514651258476
  - 0.17264030495425686
  - 0.1672860700637102
  - 0.16394703049445525
  - 0.1678760663489811
  - 0.1636802128632553
  - 0.1597268140176311
  - 0.16401002276688814
  - 0.1666059775161557
  - 0.15951681468868628
  - 0.16352188220480457
  - 0.16891326737822965
  - 0.16303391620749608
  - 0.16234754008473828
  - 0.16079114767489955
  - 0.1599808331229724
  - 0.16493451973656192
  - 0.16121655370807275
  - 0.1617592130205594
  - 0.16060512396506965
  - 0.16164744622074068
  - 0.16061525762779638
  - 0.16003216459648684
  - 0.1642206089454703
  - 0.16092577355448157
  - 0.15940842946292832
  - 0.16141200810670853
  - 0.15795637795235962
  - 0.16046605707379058
  - 0.16312538977945223
  - 0.15896741027245298
  - 0.1583987814374268
  - 0.15991124894935638
  - 0.1609706089948304
  - 0.16045205848058686
  - 0.15559266065247357
  - 0.1529405309120193
  - 0.15541654877597466
  - 0.16045478417072445
  - 0.16102985269390047
  - 0.15834674978395924
  - 0.15316521102795377
  val_loss:
  - 0.29734891951084136
  - 0.2853026163065806
  - 0.23184308607596904
  - 0.22006177413277328
  - 0.20342857955256477
  - 0.20129437022842467
  - 0.18961070146178827
  - 0.1946948990225792
  - 0.1970863503520377
  - 0.19865133840357885
  - 0.19408059335546568
  - 0.18988457508385181
  - 0.1797778132604435
  - 0.17792674590600654
  - 0.17494741617701948
  - 0.17731583071872592
  - 0.17345176840899512
  - 0.1726633661892265
  - 0.174494112317916
  - 0.17096736055100337
  - 0.17384908528765664
  - 0.17190141696482897
  - 0.17345057765487581
  - 0.16750871611293405
  - 0.16591099399374798
  - 0.17484866408631206
  - 0.16814131365390494
  - 0.15989403001731262
  - 0.17233195510925725
  - 0.1656514651258476
  - 0.17264030495425686
  - 0.1672860700637102
  - 0.16394703049445525
  - 0.1678760663489811
  - 0.1636802128632553
  - 0.1597268140176311
  - 0.16401002276688814
  - 0.1666059775161557
  - 0.15951681468868628
  - 0.16352188220480457
  - 0.16891326737822965
  - 0.16303391620749608
  - 0.16234754008473828
  - 0.16079114767489955
  - 0.1599808331229724
  - 0.16493451973656192
  - 0.16121655370807275
  - 0.1617592130205594
  - 0.16060512396506965
  - 0.16164744622074068
  - 0.1374366447329521
  - 0.16003216459648684
  - 0.1642206089454703
  - 0.16092577355448157
  - 0.15940842946292832
  - 0.16141200810670853
  - 0.15795637795235962
  - 0.16046605707379058
  - 0.16312538977945223
  - 0.15896741027245298
  - 0.1583987814374268
  - 0.15991124894935638
  - 0.1609706089948304
  - 0.16045205848058686
  - 0.15559266065247357
  - 0.1529405309120193
  - 0.15541654877597466
  - 0.16045478417072445
  - 0.16102985269390047
  - 0.15834674978395924
  - 0.15316521102795377
