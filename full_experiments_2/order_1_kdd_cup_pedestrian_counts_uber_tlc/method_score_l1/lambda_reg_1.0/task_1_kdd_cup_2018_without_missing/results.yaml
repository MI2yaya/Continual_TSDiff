best_checkpoint: full_experiments_2/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_score_l1/lambda_reg_1.0/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 1.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l1
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.45509830130813556
  NRMSE: 0.8309103551074333
  mean_wQuantileLoss: 0.34709167257014417
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.3960146229946986
  - 0.2759790992131457
  - 0.23283852532040328
  - 0.22300918644759804
  - 0.20068496430758387
  - 0.198243219521828
  - 0.19414526963373646
  - 0.1938666274654679
  - 0.18613738240674138
  - 0.19026548753026873
  - 0.17987903690664098
  - 0.17914098309120163
  - 0.18327541562030092
  - 0.18526556552387774
  - 0.1751287473598495
  - 0.17511247500078753
  - 0.1762136110337451
  - 0.17557854199549183
  - 0.17306286707753316
  - 0.17462075100047514
  - 0.17363551794551313
  - 0.176329655922018
  - 0.168062528478913
  - 0.17348734295228496
  - 0.16717419523047283
  - 0.1655475203297101
  - 0.17415542830713093
  - 0.1691632549627684
  - 0.16577088239137083
  - 0.1709046548930928
  - 0.16687712009297684
  - 0.16121695440961048
  - 0.1601649567601271
  - 0.16536704957252368
  - 0.16865484218578786
  - 0.1718704037484713
  - 0.16786022542510182
  - 0.165457610914018
  - 0.16625023575033993
  - 0.16428762598661706
  - 0.16528636391740292
  - 0.164410509634763
  - 0.1633000960573554
  - 0.16384324611863121
  - 0.15746176976244897
  - 0.16087669011903927
  - 0.16679899854352698
  - 0.16208057443145663
  - 0.15955099707935005
  - 0.1649526609107852
  - 0.15681353531545028
  - 0.16163539403351024
  - 0.15361125790514052
  - 0.15801934769842774
  - 0.1632709187688306
  - 0.15541186823975295
  - 0.1591719946009107
  - 0.162515890377108
  - 0.1605081635643728
  - 0.1547297487850301
  - 0.1577798862126656
  - 0.1584610550198704
  - 0.16018339397851378
  - 0.15507621801225469
  - 0.15228524123085663
  - 0.15936707193031907
  - 0.15567694103810936
  - 0.1554231838672422
  - 0.1599381620180793
  - 0.1581579115591012
  - 0.15612994006369263
  val_loss:
  - 0.31019802689552306
  - 0.2759790992131457
  - 0.23283852532040328
  - 0.22300918644759804
  - 0.20068496430758387
  - 0.198243219521828
  - 0.19414526963373646
  - 0.1938666274654679
  - 0.18613738240674138
  - 0.19026548753026873
  - 0.17987903690664098
  - 0.17914098309120163
  - 0.18327541562030092
  - 0.18526556552387774
  - 0.1751287473598495
  - 0.17511247500078753
  - 0.1762136110337451
  - 0.17557854199549183
  - 0.17306286707753316
  - 0.17462075100047514
  - 0.17363551794551313
  - 0.176329655922018
  - 0.168062528478913
  - 0.17348734295228496
  - 0.16717419523047283
  - 0.1655475203297101
  - 0.17415542830713093
  - 0.1691632549627684
  - 0.16577088239137083
  - 0.1709046548930928
  - 0.16687712009297684
  - 0.16121695440961048
  - 0.1601649567601271
  - 0.16536704957252368
  - 0.16865484218578786
  - 0.1718704037484713
  - 0.16786022542510182
  - 0.165457610914018
  - 0.16625023575033993
  - 0.16428762598661706
  - 0.16528636391740292
  - 0.164410509634763
  - 0.1633000960573554
  - 0.16384324611863121
  - 0.15746176976244897
  - 0.16087669011903927
  - 0.16679899854352698
  - 0.16208057443145663
  - 0.15955099707935005
  - 0.1649526609107852
  - 0.12852748185396196
  - 0.16163539403351024
  - 0.15361125790514052
  - 0.15801934769842774
  - 0.1632709187688306
  - 0.15541186823975295
  - 0.1591719946009107
  - 0.162515890377108
  - 0.1605081635643728
  - 0.1547297487850301
  - 0.1577798862126656
  - 0.1584610550198704
  - 0.16018339397851378
  - 0.15507621801225469
  - 0.15228524123085663
  - 0.15936707193031907
  - 0.15567694103810936
  - 0.1554231838672422
  - 0.1599381620180793
  - 0.1581579115591012
  - 0.15612994006369263
