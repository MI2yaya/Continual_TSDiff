best_checkpoint: full_experiments_3/order_3_pedestrian_counts_kdd_cup_uber_tlc/method_dropout/dropout_rate_0.1/task_2_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.1
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.33561946561348593
  NRMSE: 0.6987159103450981
  mean_wQuantileLoss: 0.2608401902891822
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.45924912171904
  - 0.31599461915902793
  - 0.262446001986973
  - 0.23661644058302045
  - 0.21656667557545006
  - 0.22119605354964733
  - 0.20934998360462487
  - 0.21103560749907047
  - 0.1990261118626222
  - 0.19549995940178633
  - 0.1945109730004333
  - 0.19251449464354664
  - 0.19984363170806319
  - 0.18870330165373161
  - 0.1918026374769397
  - 0.1887249741703272
  - 0.18941515928599983
  - 0.19463124126195908
  - 0.18599642999470234
  - 0.18440262973308563
  - 0.18583076319191605
  - 0.18257634423207492
  - 0.1886990291532129
  - 0.18061288294848055
  - 0.18757391307735816
  - 0.18185375211760402
  - 0.1853052094229497
  - 0.18158149009104818
  - 0.1749042478040792
  - 0.179231142741628
  - 0.17298404418397695
  - 0.18057429481996223
  - 0.17420760862296447
  - 0.17501563753467053
  - 0.17729748506098986
  - 0.17965279961936176
  - 0.17733457445865497
  - 0.17488461104221642
  - 0.1760042256792076
  - 0.17929124855436385
  - 0.175868249789346
  - 0.17009075649548322
  - 0.1716200489900075
  - 0.1712926507461816
  - 0.1744107230915688
  - 0.17244282946921885
  - 0.17704691784456372
  - 0.16968244733288884
  - 0.17162694659782574
  - 0.17006897210376337
  - 0.16936561034526676
  - 0.16956761345500126
  - 0.17074535437859595
  - 0.16696768027031794
  - 0.17588724719826132
  - 0.1727857130463235
  - 0.17087952105794102
  - 0.1716616310295649
  - 0.16827015578746796
  - 0.17341093125287443
  - 0.17116438271477818
  - 0.1663088243221864
  - 0.16846791532589123
  - 0.1713107935502194
  - 0.16327183617977425
  - 0.16460651502711698
  - 0.16903163789538667
  - 0.16660179133759812
  - 0.16847679391503334
  - 0.16616149008041248
  - 0.16843628871720284
  val_loss:
  - 0.27908477783203123
  - 0.31599461915902793
  - 0.262446001986973
  - 0.23661644058302045
  - 0.21656667557545006
  - 0.22119605354964733
  - 0.20934998360462487
  - 0.21103560749907047
  - 0.1990261118626222
  - 0.19549995940178633
  - 0.1945109730004333
  - 0.19251449464354664
  - 0.19984363170806319
  - 0.18870330165373161
  - 0.1918026374769397
  - 0.1887249741703272
  - 0.18941515928599983
  - 0.19463124126195908
  - 0.18599642999470234
  - 0.18440262973308563
  - 0.18583076319191605
  - 0.18257634423207492
  - 0.1886990291532129
  - 0.18061288294848055
  - 0.18757391307735816
  - 0.18185375211760402
  - 0.1853052094229497
  - 0.18158149009104818
  - 0.1749042478040792
  - 0.179231142741628
  - 0.17298404418397695
  - 0.18057429481996223
  - 0.17420760862296447
  - 0.17501563753467053
  - 0.17729748506098986
  - 0.17965279961936176
  - 0.17733457445865497
  - 0.17488461104221642
  - 0.1760042256792076
  - 0.17929124855436385
  - 0.175868249789346
  - 0.17009075649548322
  - 0.1716200489900075
  - 0.1712926507461816
  - 0.1744107230915688
  - 0.17244282946921885
  - 0.17704691784456372
  - 0.16968244733288884
  - 0.17162694659782574
  - 0.17006897210376337
  - 0.11879940181970597
  - 0.16956761345500126
  - 0.17074535437859595
  - 0.16696768027031794
  - 0.17588724719826132
  - 0.1727857130463235
  - 0.17087952105794102
  - 0.1716616310295649
  - 0.16827015578746796
  - 0.17341093125287443
  - 0.17116438271477818
  - 0.1663088243221864
  - 0.16846791532589123
  - 0.1713107935502194
  - 0.16327183617977425
  - 0.16460651502711698
  - 0.16903163789538667
  - 0.16660179133759812
  - 0.16847679391503334
  - 0.16616149008041248
  - 0.16843628871720284
