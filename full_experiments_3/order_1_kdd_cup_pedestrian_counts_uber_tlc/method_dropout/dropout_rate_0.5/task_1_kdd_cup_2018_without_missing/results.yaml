best_checkpoint: full_experiments_3/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_dropout/dropout_rate_0.5/task_1_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.5
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.355291024989417
  NRMSE: 0.7354852035425068
  mean_wQuantileLoss: 0.2863003497421912
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.4581599289085716
  - 0.36007781606167555
  - 0.3223032715031877
  - 0.2947451549116522
  - 0.28325667220633477
  - 0.270922445692122
  - 0.2651558208744973
  - 0.25711141573265195
  - 0.2567546289646998
  - 0.2453160877339542
  - 0.24991518852766603
  - 0.24464830022770911
  - 0.23682469851337373
  - 0.2465636256383732
  - 0.23146346327848732
  - 0.24051144975237548
  - 0.22994748887140304
  - 0.2299838779726997
  - 0.22841000254265964
  - 0.22925040079280734
  - 0.2280088788829744
  - 0.22776182857342064
  - 0.23009055480360985
  - 0.2283089489210397
  - 0.2224342825356871
  - 0.22708970005623996
  - 0.22986576217226684
  - 0.225453847553581
  - 0.22934042196720839
  - 0.225099740549922
  - 0.22737351001705974
  - 0.22831209260039032
  - 0.22640894853975624
  - 0.22876541153527796
  - 0.22506438253913075
  - 0.22002241504378617
  - 0.22274471796117723
  - 0.22703482769429684
  - 0.22079740662593395
  - 0.22196802066173404
  - 0.22668363410048187
  - 0.23268415872007608
  - 0.22349436522927135
  - 0.2276711668819189
  - 0.21864980296231806
  - 0.2229852315504104
  - 0.22121275076642632
  - 0.22345436445903033
  - 0.21913239499554038
  - 0.22463056538254023
  - 0.2296894183382392
  - 0.21331886091502383
  - 0.22404011490289122
  - 0.22568333242088556
  - 0.22309225413482636
  - 0.22489133989438415
  - 0.21931050857529044
  - 0.220299051143229
  - 0.2221149797551334
  - 0.2214741628849879
  - 0.21917376189958304
  - 0.22666511044371873
  - 0.2190618192544207
  - 0.22504507552366704
  - 0.21376015641726553
  - 0.2199845340801403
  - 0.22058254678267986
  - 0.22331166290678084
  - 0.2208995465771295
  - 0.22075506125111133
  - 0.2209512849804014
  val_loss:
  - 0.3503122627735138
  - 0.36007781606167555
  - 0.3223032715031877
  - 0.2947451549116522
  - 0.28325667220633477
  - 0.270922445692122
  - 0.2651558208744973
  - 0.25711141573265195
  - 0.2567546289646998
  - 0.2453160877339542
  - 0.24991518852766603
  - 0.24464830022770911
  - 0.23682469851337373
  - 0.2465636256383732
  - 0.23146346327848732
  - 0.24051144975237548
  - 0.22994748887140304
  - 0.2299838779726997
  - 0.22841000254265964
  - 0.22925040079280734
  - 0.2280088788829744
  - 0.22776182857342064
  - 0.23009055480360985
  - 0.2283089489210397
  - 0.2224342825356871
  - 0.22708970005623996
  - 0.22986576217226684
  - 0.225453847553581
  - 0.22934042196720839
  - 0.225099740549922
  - 0.22737351001705974
  - 0.22831209260039032
  - 0.22640894853975624
  - 0.22876541153527796
  - 0.22506438253913075
  - 0.22002241504378617
  - 0.22274471796117723
  - 0.22703482769429684
  - 0.22079740662593395
  - 0.22196802066173404
  - 0.22668363410048187
  - 0.23268415872007608
  - 0.22349436522927135
  - 0.2276711668819189
  - 0.21864980296231806
  - 0.2229852315504104
  - 0.22121275076642632
  - 0.22345436445903033
  - 0.21913239499554038
  - 0.22463056538254023
  - 0.21245334446430206
  - 0.21331886091502383
  - 0.22404011490289122
  - 0.22568333242088556
  - 0.22309225413482636
  - 0.22489133989438415
  - 0.21931050857529044
  - 0.220299051143229
  - 0.2221149797551334
  - 0.2214741628849879
  - 0.21917376189958304
  - 0.22666511044371873
  - 0.2190618192544207
  - 0.22504507552366704
  - 0.21376015641726553
  - 0.2199845340801403
  - 0.22058254678267986
  - 0.22331166290678084
  - 0.2208995465771295
  - 0.22075506125111133
  - 0.2209512849804014
