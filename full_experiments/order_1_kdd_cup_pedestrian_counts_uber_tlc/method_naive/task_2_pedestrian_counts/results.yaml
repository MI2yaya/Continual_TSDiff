best_checkpoint: full_experiments/order_1_kdd_cup_pedestrian_counts_uber_tlc/method_naive/task_2_pedestrian_counts/pedestrian_counts_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 336
  dataset: pedestrian_counts
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  l1_weight: 0.0
  l2_weight: 0.0
  lambda_reg: 0.0
  lr: 0.0005
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.21687346135322894
  NRMSE: 0.686315942638256
  mean_wQuantileLoss: 0.1744343141633016
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.4648445957573131
  - 0.3481783338356763
  - 0.310354619869031
  - 0.2643842459656298
  - 0.24448015610687435
  - 0.2252868568757549
  - 0.21138186828466132
  - 0.21385771728819236
  - 0.2039991621277295
  - 0.18098199117230251
  - 0.1818755793501623
  - 0.19490672391839325
  - 0.18230580823728815
  - 0.18199537886539474
  - 0.17106584511930123
  - 0.17311133834300563
  - 0.17440506001003087
  - 0.20447106647770852
  - 0.1660167621448636
  - 0.16697441134601831
  - 0.16246367496205494
  - 0.16708575381198898
  - 0.1774940094910562
  - 0.16385817452101037
  - 0.1841116773430258
  - 0.15932418272132054
  - 0.15903083642479032
  - 0.18755116389365867
  - 0.1612491806736216
  - 0.15746794984443113
  - 0.15973066666629165
  - 0.1659660103614442
  - 0.1588486303226091
  - 0.1571045386372134
  - 0.15759035281371325
  - 0.1575124507653527
  - 0.15674638526979834
  - 0.1564483751426451
  - 0.15369479334913194
  - 0.15558400889858603
  - 0.15545095049310476
  - 0.15099561214447021
  - 0.1548665264272131
  - 0.15140786120900884
  - 0.15002578345593065
  - 0.15252163755940273
  - 0.1515493459883146
  - 0.1555328211397864
  - 0.1550149327958934
  - 0.15102802048204467
  - 0.1476714372402057
  - 0.151193177618552
  - 0.1515848653507419
  - 0.1512833580491133
  - 0.1494679654133506
  - 0.14873535587685183
  - 0.1497204588376917
  - 0.14942145807435736
  - 0.1522816409706138
  - 0.14782922953600064
  - 0.14933323935838416
  - 0.15092713350895792
  - 0.1479300007922575
  - 0.14976322220172733
  - 0.1488575249677524
  - 0.15019141335505992
  - 0.1526580209028907
  - 0.15371553873410448
  - 0.14676545793190598
  - 0.1530743184266612
  - 0.1462317532277666
  val_loss:
  - 0.2720669284462929
  - 0.3481783338356763
  - 0.310354619869031
  - 0.2643842459656298
  - 0.24448015610687435
  - 0.2252868568757549
  - 0.21138186828466132
  - 0.21385771728819236
  - 0.2039991621277295
  - 0.18098199117230251
  - 0.1818755793501623
  - 0.19490672391839325
  - 0.18230580823728815
  - 0.18199537886539474
  - 0.17106584511930123
  - 0.17311133834300563
  - 0.17440506001003087
  - 0.20447106647770852
  - 0.1660167621448636
  - 0.16697441134601831
  - 0.16246367496205494
  - 0.16708575381198898
  - 0.1774940094910562
  - 0.16385817452101037
  - 0.1841116773430258
  - 0.15932418272132054
  - 0.15903083642479032
  - 0.18755116389365867
  - 0.1612491806736216
  - 0.15746794984443113
  - 0.15973066666629165
  - 0.1659660103614442
  - 0.1588486303226091
  - 0.1571045386372134
  - 0.15759035281371325
  - 0.1575124507653527
  - 0.15674638526979834
  - 0.1564483751426451
  - 0.15369479334913194
  - 0.15558400889858603
  - 0.15545095049310476
  - 0.15099561214447021
  - 0.1548665264272131
  - 0.15140786120900884
  - 0.15002578345593065
  - 0.15252163755940273
  - 0.1515493459883146
  - 0.1555328211397864
  - 0.1550149327958934
  - 0.15102802048204467
  - 0.10655320435762405
  - 0.151193177618552
  - 0.1515848653507419
  - 0.1512833580491133
  - 0.1494679654133506
  - 0.14873535587685183
  - 0.1497204588376917
  - 0.14942145807435736
  - 0.1522816409706138
  - 0.14782922953600064
  - 0.14933323935838416
  - 0.15092713350895792
  - 0.1479300007922575
  - 0.14976322220172733
  - 0.1488575249677524
  - 0.15019141335505992
  - 0.1526580209028907
  - 0.15371553873410448
  - 0.14676545793190598
  - 0.1530743184266612
  - 0.1462317532277666
