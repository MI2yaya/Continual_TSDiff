best_checkpoint: full_experiments_3/order_3_pedestrian_counts_kdd_cup_uber_tlc/method_naive/task_3_uber_tlc_hourly/uber_tlc_hourly_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 336
  dataset: uber_tlc_hourly
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.0
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: false
  lambda_reg: 0.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 2
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.20819434240769868
  NRMSE: 0.5001779840365809
  mean_wQuantileLoss: 0.17398871263763044
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  - 72
  - 73
  - 74
  - 75
  - 76
  - 77
  - 78
  - 79
  - 80
  train_loss:
  - 0.4880399403627962
  - 0.3395194399636239
  - 0.31286079611163586
  - 0.2936811709078029
  - 0.29676260880660266
  - 0.29017070995178074
  - 0.2878294549882412
  - 0.28446086950134486
  - 0.2806785674765706
  - 0.28047520213294774
  - 0.2718180932570249
  - 0.27062983135692775
  - 0.26897136226762086
  - 0.2685751976678148
  - 0.2624406003160402
  - 0.2708633632864803
  - 0.26251810835674405
  - 0.2609661752358079
  - 0.2610827119788155
  - 0.2575906905112788
  - 0.2577194208279252
  - 0.2557712427806109
  - 0.2528944725636393
  - 0.25911186379380524
  - 0.25449602771550417
  - 0.25600663176737726
  - 0.25417212629690766
  - 0.25371048192027956
  - 0.25555878796149045
  - 0.25423799199052155
  - 0.25259210797958076
  - 0.2505190708907321
  - 0.2506265144329518
  - 0.25173113658092916
  - 0.24736637179739773
  - 0.2486055406043306
  - 0.25181832374073565
  - 0.24571223079692572
  - 0.2483192167710513
  - 0.24825644248630852
  - 0.24701287073548883
  - 0.24485999823082238
  - 0.2424726001918316
  - 0.24949592805933207
  - 0.24319754529278725
  - 0.2449688819469884
  - 0.2410583266755566
  - 0.24429476005025208
  - 0.24628297367598861
  - 0.24838650692254305
  - 0.2502311847638339
  - 0.2490645624930039
  - 0.23973198526073247
  - 0.24694143899250776
  - 0.23762085323687643
  - 0.2422223020112142
  - 0.245161616592668
  - 0.23906177119351923
  - 0.23709422908723354
  - 0.23343466618098319
  - 0.23879096924792975
  - 0.24166056455578655
  - 0.23840394848957658
  - 0.238845766056329
  - 0.23840065603144467
  - 0.243612494552508
  - 0.2437342373887077
  - 0.23516032134648412
  - 0.23962329921778291
  - 0.2430636138888076
  - 0.2385657859267667
  - 0.24015661037992686
  - 0.24192131648305804
  - 0.23923157854005694
  - 0.23861978377681226
  - 0.23387236532289535
  - 0.23891285702120513
  - 0.24133395357057452
  - 0.2428832509322092
  - 0.23829883988946676
  val_loss:
  - 0.29435610920190813
  - 0.3395194399636239
  - 0.31286079611163586
  - 0.2936811709078029
  - 0.29676260880660266
  - 0.29017070995178074
  - 0.2878294549882412
  - 0.28446086950134486
  - 0.2806785674765706
  - 0.28047520213294774
  - 0.2718180932570249
  - 0.27062983135692775
  - 0.26897136226762086
  - 0.2685751976678148
  - 0.2624406003160402
  - 0.2708633632864803
  - 0.26251810835674405
  - 0.2609661752358079
  - 0.2610827119788155
  - 0.2575906905112788
  - 0.2577194208279252
  - 0.2557712427806109
  - 0.2528944725636393
  - 0.25911186379380524
  - 0.25449602771550417
  - 0.25600663176737726
  - 0.25417212629690766
  - 0.25371048192027956
  - 0.25555878796149045
  - 0.25423799199052155
  - 0.25259210797958076
  - 0.2505190708907321
  - 0.2506265144329518
  - 0.25173113658092916
  - 0.24736637179739773
  - 0.2486055406043306
  - 0.25181832374073565
  - 0.24571223079692572
  - 0.2483192167710513
  - 0.24825644248630852
  - 0.24701287073548883
  - 0.24485999823082238
  - 0.2424726001918316
  - 0.24949592805933207
  - 0.24319754529278725
  - 0.2449688819469884
  - 0.2410583266755566
  - 0.24429476005025208
  - 0.24628297367598861
  - 0.24838650692254305
  - 0.243820396065712
  - 0.2490645624930039
  - 0.23973198526073247
  - 0.24694143899250776
  - 0.23762085323687643
  - 0.2422223020112142
  - 0.245161616592668
  - 0.23906177119351923
  - 0.23709422908723354
  - 0.23343466618098319
  - 0.23879096924792975
  - 0.24166056455578655
  - 0.23840394848957658
  - 0.238845766056329
  - 0.23840065603144467
  - 0.243612494552508
  - 0.2437342373887077
  - 0.23516032134648412
  - 0.23962329921778291
  - 0.2430636138888076
  - 0.2385657859267667
  - 0.24015661037992686
  - 0.24192131648305804
  - 0.23923157854005694
  - 0.23861978377681226
  - 0.23387236532289535
  - 0.23891285702120513
  - 0.24133395357057452
  - 0.2428832509322092
  - 0.23829883988946676
