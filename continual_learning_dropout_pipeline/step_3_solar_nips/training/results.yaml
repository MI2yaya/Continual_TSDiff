best_checkpoint: null
config:
  batch_size: 64
  context_length: 336
  dataset: solar_nips
  device: cuda:0
  diffusion_config: diffusion_small_config
  dropout_rate: 0.1
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: false
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  resume_from_checkpoint: ./continual_learning_dropout_pipeline/step_2_pedestrian_counts/training/pedestrian_counts_checkpoint_best.pth
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 8
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.5119989412569085
  NRMSE: 1.1493538736053
  mean_wQuantileLoss: 0.4248029491706236
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 102
  - 103
  - 104
  - 105
  - 106
  - 107
  - 108
  - 109
  - 110
  - 111
  - 112
  - 113
  - 114
  - 115
  - 116
  - 117
  - 118
  - 119
  - 120
  - 121
  - 122
  - 123
  - 124
  - 125
  - 126
  - 127
  - 128
  - 129
  - 130
  - 131
  - 132
  - 133
  - 134
  - 135
  - 136
  - 137
  - 138
  - 139
  - 140
  - 141
  - 142
  - 143
  - 144
  - 145
  - 146
  - 147
  - 148
  - 149
  - 150
  - 151
  - 152
  - 153
  - 154
  - 155
  - 156
  - 157
  - 158
  - 159
  - 160
  - 161
  - 162
  - 163
  - 164
  - 165
  - 166
  - 167
  - 168
  - 169
  - 170
  - 171
  train_loss:
  - 0.24714696942828596
  - 0.15740787464892492
  - 0.1486740947002545
  - 0.14628600142896175
  - 0.14572821598267183
  - 0.13535045366734266
  - 0.13535558769945055
  - 0.13392082531936467
  - 0.13297122961375862
  - 0.1361619954695925
  - 0.13299608568195254
  - 0.13149184954818338
  - 0.13183714565820992
  - 0.13355806755134836
  - 0.12928262882633135
  - 0.13044052507029846
  - 0.12450371211161837
  - 0.12692190433153883
  - 0.12752555502811447
  - 0.1257205361034721
  - 0.1248847238603048
  - 0.1247007017955184
  - 0.1262394569348544
  - 0.1248736153356731
  - 0.1249911566847004
  - 0.12156846048310399
  - 0.12286416214192286
  - 0.12162855465430766
  - 0.12424008292146027
  - 0.12045864411629736
  - 0.12454570265254006
  - 0.12234341981820762
  - 0.12234053947031498
  - 0.12022253806935623
  - 0.12515754264313728
  - 0.11806667904602364
  - 0.11919805034995079
  - 0.12112123798578978
  - 0.12126461730804294
  - 0.11952271056361496
  - 0.11744525970425457
  - 0.11911357421195135
  - 0.1183857275173068
  - 0.11977761529851705
  - 0.1195753937936388
  - 0.12061074411030859
  - 0.1174946281244047
  - 0.11990575701929629
  - 0.12024451972683892
  - 0.12324172456283122
  - 0.11895458737853914
  - 0.1188393498887308
  - 0.11752121482277289
  - 0.11892293341225013
  - 0.11540117079857737
  - 0.11547101236646995
  - 0.11632593424292281
  - 0.11853069922653958
  - 0.1140844248002395
  - 0.1161499511799775
  - 0.1178614996606484
  - 0.11815990979084745
  - 0.11512347753159702
  - 0.11777559068286791
  - 0.11608300934312865
  - 0.11665758601156995
  - 0.11638813390163705
  - 0.11453132220776752
  - 0.11356287111993879
  - 0.11568810022436082
  val_loss:
  - 0.24714696942828596
  - 0.15740787464892492
  - 0.1486740947002545
  - 0.14628600142896175
  - 0.14572821598267183
  - 0.13535045366734266
  - 0.13535558769945055
  - 0.13392082531936467
  - 0.13297122961375862
  - 0.1361619954695925
  - 0.13299608568195254
  - 0.13149184954818338
  - 0.13183714565820992
  - 0.13355806755134836
  - 0.12928262882633135
  - 0.13044052507029846
  - 0.12450371211161837
  - 0.12692190433153883
  - 0.12752555502811447
  - 0.1257205361034721
  - 0.1248847238603048
  - 0.1247007017955184
  - 0.1262394569348544
  - 0.1248736153356731
  - 0.1249911566847004
  - 0.12156846048310399
  - 0.12286416214192286
  - 0.12162855465430766
  - 0.12424008292146027
  - 0.12045864411629736
  - 0.12454570265254006
  - 0.12234341981820762
  - 0.12234053947031498
  - 0.12022253806935623
  - 0.12515754264313728
  - 0.11806667904602364
  - 0.11919805034995079
  - 0.12112123798578978
  - 0.12126461730804294
  - 0.11952271056361496
  - 0.11744525970425457
  - 0.11911357421195135
  - 0.1183857275173068
  - 0.11977761529851705
  - 0.1195753937936388
  - 0.12061074411030859
  - 0.1174946281244047
  - 0.11990575701929629
  - 0.12024451972683892
  - 0.0961685801545779
  - 0.11895458737853914
  - 0.1188393498887308
  - 0.11752121482277289
  - 0.11892293341225013
  - 0.11540117079857737
  - 0.11547101236646995
  - 0.11632593424292281
  - 0.11853069922653958
  - 0.1140844248002395
  - 0.1161499511799775
  - 0.1178614996606484
  - 0.11815990979084745
  - 0.11512347753159702
  - 0.11777559068286791
  - 0.11608300934312865
  - 0.11665758601156995
  - 0.11638813390163705
  - 0.11453132220776752
  - 0.11356287111993879
  - 0.11568810022436082
