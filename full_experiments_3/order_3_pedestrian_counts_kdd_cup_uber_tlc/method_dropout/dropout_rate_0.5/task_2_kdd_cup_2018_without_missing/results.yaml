best_checkpoint: full_experiments_3/order_3_pedestrian_counts_kdd_cup_uber_tlc/method_dropout/dropout_rate_0.5/task_2_kdd_cup_2018_without_missing/kdd_cup_2018_without_missing_checkpoint_best.pth
config:
  batch_size: 64
  context_length: 312
  dataset: kdd_cup_2018_without_missing
  device: cuda:1
  diffusion_config: diffusion_small_config
  dropout_rate: 0.5
  eval_every: 50
  freq: H
  gradient_clip_val: 0.5
  init_skip: true
  lambda_reg: 0.0
  lr: 0.001
  max_epochs: 1000
  model: unconditional
  normalization: mean
  num_batches_per_epoch: 128
  num_samples: 16
  prediction_length: 24
  sampler: ddpm
  sampler_params:
    guidance: quantile
    scale: 1
  score_loss_type: l2
  setup: forecasting
  use_features: false
  use_lags: true
  use_validation_set: true
metrics:
- ND: 0.3373096015428023
  NRMSE: 0.7019642866908472
  mean_wQuantileLoss: 0.27188630479983233
  missing_scenario: none
  missing_values: 0
training_history:
  epochs:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
  - 50
  - 51
  - 52
  - 53
  - 54
  - 55
  - 56
  - 57
  - 58
  - 59
  - 60
  - 61
  - 62
  - 63
  - 64
  - 65
  - 66
  - 67
  - 68
  - 69
  - 70
  - 71
  train_loss:
  - 0.4624321816954762
  - 0.3628725645830855
  - 0.3171561500057578
  - 0.29900866583921015
  - 0.2789539961377159
  - 0.25889660557731986
  - 0.2632619122741744
  - 0.24407980346586555
  - 0.2516389775555581
  - 0.24211239302530885
  - 0.24286305718123913
  - 0.24128412641584873
  - 0.2366723142331466
  - 0.23448558256495744
  - 0.24225825152825564
  - 0.23658770637121052
  - 0.23162393434904516
  - 0.22574491635896266
  - 0.2348035495961085
  - 0.23156809818465263
  - 0.22938546282239258
  - 0.22174495016224682
  - 0.22803826711606234
  - 0.21930431039072573
  - 0.22764545015525073
  - 0.23052849131636322
  - 0.22397190879564732
  - 0.22192852350417525
  - 0.22316272219177336
  - 0.22198104916606098
  - 0.22521322639659047
  - 0.2212083397898823
  - 0.22796394932083786
  - 0.2227468608180061
  - 0.22776623454410583
  - 0.22539380786474794
  - 0.22529709711670876
  - 0.22126067645149305
  - 0.22253605723381042
  - 0.222256914479658
  - 0.22224867541808635
  - 0.2228218086529523
  - 0.22495570802129805
  - 0.21740568045061082
  - 0.2216779360314831
  - 0.22426536690909415
  - 0.2185912384884432
  - 0.22515080799348652
  - 0.22455122019164264
  - 0.2195713219116442
  - 0.21990337362512946
  - 0.21581878140568733
  - 0.21798192290589213
  - 0.22028692218009382
  - 0.2191884402418509
  - 0.2164698639535345
  - 0.21663296723272651
  - 0.21906409226357937
  - 0.21900309110060334
  - 0.21988794615026563
  - 0.2198216945398599
  - 0.2189524251734838
  - 0.21660275594331324
  - 0.22546541329938918
  - 0.22594959940761328
  - 0.21450532297603786
  - 0.2158403202192858
  - 0.21712461474817246
  - 0.21344355784822255
  - 0.21331704687327147
  - 0.2116701154736802
  val_loss:
  - 0.3025003135204315
  - 0.3628725645830855
  - 0.3171561500057578
  - 0.29900866583921015
  - 0.2789539961377159
  - 0.25889660557731986
  - 0.2632619122741744
  - 0.24407980346586555
  - 0.2516389775555581
  - 0.24211239302530885
  - 0.24286305718123913
  - 0.24128412641584873
  - 0.2366723142331466
  - 0.23448558256495744
  - 0.24225825152825564
  - 0.23658770637121052
  - 0.23162393434904516
  - 0.22574491635896266
  - 0.2348035495961085
  - 0.23156809818465263
  - 0.22938546282239258
  - 0.22174495016224682
  - 0.22803826711606234
  - 0.21930431039072573
  - 0.22764545015525073
  - 0.23052849131636322
  - 0.22397190879564732
  - 0.22192852350417525
  - 0.22316272219177336
  - 0.22198104916606098
  - 0.22521322639659047
  - 0.2212083397898823
  - 0.22796394932083786
  - 0.2227468608180061
  - 0.22776623454410583
  - 0.22539380786474794
  - 0.22529709711670876
  - 0.22126067645149305
  - 0.22253605723381042
  - 0.222256914479658
  - 0.22224867541808635
  - 0.2228218086529523
  - 0.22495570802129805
  - 0.21740568045061082
  - 0.2216779360314831
  - 0.22426536690909415
  - 0.2185912384884432
  - 0.22515080799348652
  - 0.22455122019164264
  - 0.2195713219116442
  - 0.16733499616384506
  - 0.21581878140568733
  - 0.21798192290589213
  - 0.22028692218009382
  - 0.2191884402418509
  - 0.2164698639535345
  - 0.21663296723272651
  - 0.21906409226357937
  - 0.21900309110060334
  - 0.21988794615026563
  - 0.2198216945398599
  - 0.2189524251734838
  - 0.21660275594331324
  - 0.22546541329938918
  - 0.22594959940761328
  - 0.21450532297603786
  - 0.2158403202192858
  - 0.21712461474817246
  - 0.21344355784822255
  - 0.21331704687327147
  - 0.2116701154736802
